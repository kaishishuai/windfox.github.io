<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>综合设计 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="安装环境创建一个conda环境 12345conda info -e #查看当前系统有哪些python环境conda create -n tf-pose python&#x3D;3.7.10activate tf-pose #激活环境  需要的环境  opencv4.5.0 libatlas-base-dev-3.10.3  准备数据集参考：https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;3d9436b">
<meta property="og:type" content="article">
<meta property="og:title" content="综合设计">
<meta property="og:url" content="http://example.com/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="安装环境创建一个conda环境 12345conda info -e #查看当前系统有哪些python环境conda create -n tf-pose python&#x3D;3.7.10activate tf-pose #激活环境  需要的环境  opencv4.5.0 libatlas-base-dev-3.10.3  准备数据集参考：https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;3d9436b">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://gitee.com/gitzuo/blog2021/raw/master/blog2022/image-20210817124854046.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817155210209.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817165746682.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817170126941.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817172339074.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817172948282.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817175821175.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818143913605.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818212837624.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818212917529.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818223551339.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818223716643.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818230115971.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210821123855565.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818235538040.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210821111959296.png">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210821142435913.png">
<meta property="article:published_time" content="2022-05-04T07:20:21.000Z">
<meta property="article:modified_time" content="2022-05-04T07:32:59.675Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/gitzuo/blog2021/raw/master/blog2022/image-20210817124854046.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.1.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-综合设计" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1/" class="article-date">
  <time class="dt-published" datetime="2022-05-04T07:20:21.000Z" itemprop="datePublished">2022-05-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      综合设计
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h1><p>创建一个conda环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda info -e #查看当前系统有哪些python环境</span><br><span class="line"></span><br><span class="line">conda create -n tf-pose python=3.7.10</span><br><span class="line"></span><br><span class="line">activate tf-pose #激活环境</span><br></pre></td></tr></table></figure>

<p>需要的环境</p>
<ul>
<li>opencv4.5.0</li>
<li>libatlas-base-dev-3.10.3</li>
</ul>
<h1 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h1><p>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3d9436b4cb66">https://www.jianshu.com/p/3d9436b4cb66</a></p>
<p>标注数据集：labelimg</p>
<p>使用的数据集：imagenet n04589890（100张）</p>
<p>ps:模型文件夹从train改为了train_my</p>
<h1 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h1><p>使用预训练模型：ssd-v2-oidv4（git：<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md%EF%BC%89">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md）</a></p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/0e5f9df4686a">https://www.jianshu.com/p/0e5f9df4686a</a></p>
<ol>
<li>在此目录下运行下面命令</li>
</ol>
<p><img src="https://gitee.com/gitzuo/blog2021/raw/master/blog2022/image-20210817124854046.png" alt="image-20210817124854046"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/model_main.py --pipeline_config_path=training_my/ssdlite_mobilenet_v2_coco.config --model_dir=training_my --alsologtostderr</span><br></pre></td></tr></table></figure>

<ol>
<li>查看模型训练情况</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=training</span><br></pre></td></tr></table></figure>

<p><a href="http://kunpc:6006查看/">http://KUNPC:6006查看</a></p>
<h2 id="遇到问题："><a href="#遇到问题：" class="headerlink" title="遇到问题："></a>遇到问题：</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.</span><br><span class="line">  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.</span><br><span class="line">         [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at E:\Anaconda3-\machinelearning\envs\tf-pose\lib\site-packages\tf_slim-1.1.0-py3.7.egg\tf_slim\layers\layers.py:1089) ]]</span><br><span class="line"></span><br><span class="line">         [[Loss/Cast_34/_7177]]</span><br><span class="line">  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.</span><br><span class="line">         [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at E:\Anaconda3-\machinelearning\envs\tf-pose\lib\site-packages\tf_slim-1.1.0-py3.7.egg\tf_slim\layers\layers.py:1089) ]]</span><br><span class="line"></span><br><span class="line">0 successful operations.</span><br><span class="line">0 derived errors ignored.</span><br><span class="line"></span><br><span class="line">Errors may have originated from an input operation.</span><br><span class="line">Input Source operations connected to node FeatureExtractor/MobilenetV2/Conv/Conv2D:</span><br><span class="line"> FeatureExtractor/MobilenetV2/Conv/weights/read (defined at E:\Anaconda3-\machinelearning\envs\tf-pose\lib\site-packages\tf_slim-1.1.0-py3.7.egg\tf_slim\ops\variables.py:256)</span><br><span class="line"> FeatureExtractor/MobilenetV2/MobilenetV2/input (defined at D:\code\Tensorflow\useless\models\research\slim\nets\mobilenet\mobilenet.py:368)</span><br></pre></td></tr></table></figure>

<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#添加下面两行，</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.environ[&#x27;CUDA_VISIBLE_DEVICES&#x27;] = &#x27;/gpu:0&#x27;</span><br></pre></td></tr></table></figure>

<p>或者：可能是Tensorflow-gpu版本太高，我报错时为1.12，可以将其降为1.9.0<br>pip install tensorflow-gpu&#x3D;&#x3D;1.9.0或者conda install tensorflow-gpu&#x3D;&#x3D;1.9.0</p>
<p>Note：我不知道是不是同时需要将cpu版本的tensorflow也降下来，如果你还有问题，则继续执行</p>
<p>pip install tensorflow&#x3D;&#x3D;1.9.0或者conda install tensorflow&#x3D;&#x3D;1.9.0</p>
<p>不报错了，但速度慢的一匹，</p>
<h3 id="查看任务管理器：然而还是没有使用gpu加速，只是能运行了而已（gpu只占用了1-）"><a href="#查看任务管理器：然而还是没有使用gpu加速，只是能运行了而已（gpu只占用了1-）" class="headerlink" title="查看任务管理器：然而还是没有使用gpu加速，只是能运行了而已（gpu只占用了1%）"></a>查看任务管理器：然而还是没有使用gpu加速，只是能运行了而已（gpu只占用了1%）</h3><p>根据这篇文章：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zlase/article/details/79261348">https://blog.csdn.net/zlase/article/details/79261348</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&#x27;a&#x27;)</span><br><span class="line">b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&#x27;b&#x27;)</span><br><span class="line">c = tf.matmul(a, b)</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br><span class="line">print(sess.run(c))</span><br></pre></td></tr></table></figure>

<p>查看出来确实是gpu在运行：</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817155210209.png" alt="image-20210817155210209"></p>
<p>非常离谱，裂开了</p>
<p>然后发现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2021-08-17 16:11:44.539426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll</span><br><span class="line">2021-08-17 16:11:44.582555: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected</span><br></pre></td></tr></table></figure>

<p>问题应该出在下面这一行，一百度，全是说没有dll文件的，但是我没有报没有dll文件的错误，gg。</p>
<p>又继续找：找到一个国外老兄有一样的问题：</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/61483632/e-tensorflow-stream-executor-cuda-cuda-driver-cc351-failed-call-to-cuinit-cuda">https://stackoverflow.com/questions/61483632/e-tensorflow-stream-executor-cuda-cuda-driver-cc351-failed-call-to-cuinit-cuda</a></p>
<p>只有个人回答他版本对不上。</p>
<p>怀疑是cuda和cudnn和tensorflow-gpu1.14.0和GTX1650对应不上</p>
<p>查看cuda版本：<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</code>可见是v10.0</p>
<p>查看cudnn版本：<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\cudnn\include\cudnn.h</code>文件</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817165746682.png" alt="image-20210817165746682"></p>
<p>发现是7.6.5版本的</p>
<p>查看N卡支持的cuda版本：（控制面板-系统信息）</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817170126941.png" alt="image-20210817170126941"></p>
<p>发现我们需要的版本是11.1.114</p>
<p>cuda下载地址：</p>
<p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p>
<p>就在要去下载的时候，突然想器上次看配置的时候这个版本应该就是10点几啊，然后发现网上的人1650用的都是10.1的cuda，看来跟这个没什么关系。</p>
<p>然后又百度到了这篇文章</p>
<p><a target="_blank" rel="noopener" href="https://bbs.csdn.net/topics/392851047">https://bbs.csdn.net/topics/392851047</a></p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817172339074.png" alt="image-20210817172339074"></p>
<p>这位老哥的问题不能说和我是一模一样，只能说是十分相似。</p>
<p>然后根据这篇文章找到了另一篇文章：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45709671/article/details/107448136">https://blog.csdn.net/weixin_45709671/article/details/107448136</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/csdnfala/article/details/91358622">https://blog.csdn.net/csdnfala/article/details/91358622</a></p>
<h4 id="根据第二篇文章"><a href="#根据第二篇文章" class="headerlink" title="根据第二篇文章:"></a>根据第二篇文章:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.constant(1)</span><br><span class="line">b = tf.constant(1)</span><br><span class="line">c = a + b</span><br><span class="line">sess = tf.Session(config =tf.ConfigProto(log_device_placement = True))</span><br><span class="line">print(sess.run(c))</span><br></pre></td></tr></table></figure>

<p>若正常应该输出2，并且在输出2之前有很长串的信息如算力(ability)、gpu的分配情况等等。</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817172948282.png" alt="image-20210817172948282"></p>
<h4 id="根据第一篇文章"><a href="#根据第一篇文章" class="headerlink" title="根据第一篇文章"></a>根据第一篇文章</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda install cudatoolkit=10.1</span><br><span class="line">conda install cudnn=7.6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pip install -i https://mirrors.aliyun.com/pypi/simple/ tensorflow==2.1</span><br><span class="line">pip install -i https://mirrors.aliyun.com/pypi/simple/ tensorflow-gpu==2.1</span><br></pre></td></tr></table></figure>

<p>检验</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"># 如果安装成功，则会输出2.1.0</span><br><span class="line"></span><br><span class="line">gpu_device_name = tf.test.gpu_device_name()</span><br><span class="line">print(gpu_device_name)</span><br><span class="line">print(tf.test.is_gpu_available())  #输出为True，则证明GPU版本的tensorflow安装成功</span><br><span class="line">#否则为CPU版本，若有需要GPU，可尝试重新安装</span><br><span class="line">#使用指令  pip install tensorflow-gpu==2.1 ，指定GPU版本</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210817175821175.png" alt="image-20210817175821175"></p>
<p>成功</p>
<p>再次运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/model_main.py --pipeline_config_path=training_my/ssdlite_mobilenet_v2_coco.config --model_dir=training_my --alsologtostderr</span><br></pre></td></tr></table></figure>

<p>还是没什么软用。还有函数出错，还是得降回1.14.0，得先删除高版本和一些东西，具体删除什么报错了再找</p>
<h4 id="第二天："><a href="#第二天：" class="headerlink" title="第二天："></a>第二天：</h4><p>英伟达控制台查看gpu使用情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi.exe -l 5  #五秒查一次</span><br></pre></td></tr></table></figure>

<p>这里发现其实英伟达的cuda版本分驱动版和软件版，驱动板就是英伟达面板里看的那个（能使用显卡的程序都需要驱动版），软件版就是跑机器学习的时候使用的</p>
<p>上面的命令查看到的cuda是驱动版，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure>

<p>查看到的是软件版，一般来说</p>
<p>驱动版的版本号高于软件版的就没问题</p>
<h4 id="另辟蹊径："><a href="#另辟蹊径：" class="headerlink" title="另辟蹊径："></a>另辟蹊径：</h4><p>突然发现：github有TF1.0和2.0的版本，尝试使用tensorflow2.2和python3.6搭建一个新环境：（之前是1.14）</p>
<p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md</a></p>
<ol>
<li>在code目录下新建一个objectdetection2的目录</li>
<li>克隆源码</li>
<li>使用虚拟环境ob，并安装tf2.2</li>
<li>按照命令执行tf2.setup.py</li>
<li>将之前的train_my文件下复制到项目目录下</li>
</ol>
<p>得到</p>
<p>gg，环境搞乱了，remake</p>
<h1 id="remake："><a href="#remake：" class="headerlink" title="remake："></a>remake：</h1><p>重新搭建tf-pose环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#删除原来的虚拟环境</span><br><span class="line">conda remove -n tf-pose --all</span><br><span class="line">#创建虚拟环境</span><br><span class="line">conda create -n tf-pose python=3.6</span><br><span class="line">#激活</span><br><span class="line">activate tf-pose</span><br><span class="line">#安装tensorflow-gpu</span><br><span class="line">conda install tensorflow-gpu==1.15.0</span><br><span class="line">#安装tf_slim</span><br><span class="line">pip install tf_slim</span><br><span class="line">#安装pycocotools</span><br><span class="line">pip install pycocotools</span><br><span class="line">#安装lvis</span><br><span class="line">pip install lvis</span><br><span class="line">#安装resnet</span><br><span class="line">pip install resnet</span><br></pre></td></tr></table></figure>

<p>报错：</p>
<p>from tensorflow.python.keras.applications import resnet50 as resnet<br>ImportError: cannot import name ‘resnet50’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#降级回1.14.0,必须得同时安装cpu和gpu版本，不然报错</span><br><span class="line">import tensorflow.compat.v1 as tf</span><br><span class="line">ModuleNotFoundError: No module named &#x27;tensorflow.compat&#x27;</span><br><span class="line"></span><br><span class="line">#安装scipy</span><br><span class="line">pip install scipy</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/builders/model_builder_tf1_test.py</span><br></pre></td></tr></table></figure>

<p>成功：</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818143913605.png" alt="image-20210818143913605"></p>
<p>训练：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/model_main.py --pipeline_config_path=training_my/ssdlite_mobilenet_v2_coco.config --model_dir=training_my --alsologtostderr</span><br></pre></td></tr></table></figure>

<p>外面的可以跑，但还是用的cpu，里面的报错:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2021-08-18 14:53:00.892597: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2</span><br><span class="line">Windows fatal exception: access violation</span><br></pre></td></tr></table></figure>

<p>外面的没使用gpu：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2021-08-18 15:06:43.280716: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2</span><br><span class="line">2021-08-18 15:06:43.282694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll</span><br><span class="line">2021-08-18 15:06:43.315183: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected</span><br><span class="line">2021-08-18 15:06:43.321281: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: LAPTOP-B9TRJB</span><br><span class="line">2021-08-18 15:06:43.321534: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: LAPTOP-B9TR</span><br></pre></td></tr></table></figure>

<p>回到解放前</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lscelory/article/details/83579062">https://blog.csdn.net/lscelory/article/details/83579062</a></p>
<p>这个博主说将CUDA_VISIBLE_DEVICES&#x3D;0添加到环境变量中去</p>
<p>然而并没有什么软用</p>
<p>这篇文章说使用legacy的train来训练</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_34289454/article/details/89611294">https://blog.csdn.net/weixin_34289454/article/details/89611294</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/legacy/train.py --pipeline_config_path=training_my/ssdlite_mobilenet_v2_coco.config --train_dir=training_my/train --alsologtostderr</span><br></pre></td></tr></table></figure>

<p>然而并没有什么软用，但是速度变快了一秒一百个step了</p>
<p>现在开始怀疑是不是代码里有什么指定使用cpu的片段</p>
<h2 id="搭建ob环境"><a href="#搭建ob环境" class="headerlink" title="搭建ob环境"></a>搭建ob环境</h2><p>在这之前先把另一个环境ob搭好，和tf-pose除了tensorflow版本不一样和没有cpu版本的之外全一样</p>
<p>但是报错：</p>
<p>ERROR: pip’s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.<br>tensorflow-gpu 2.2.0 requires gast&#x3D;&#x3D;0.3.3, but you have gast 0.4.0 which is incompatible.<br>tensorflow-gpu 2.2.0 requires h5py&lt;2.11.0,&gt;&#x3D;2.10.0, but you have h5py 3.1.0 which is incompatible.<br>tensorflow-gpu 2.2.0 requires tensorboard&lt;2.3.0,&gt;&#x3D;2.2.0, but you have tensorboard 2.6.0 which is incompatible.</p>
<p>先一一装好</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install  gast==0.3.3</span><br><span class="line">pip install h5py==2.10.0</span><br><span class="line">pip install tensorboard==2.2.0</span><br></pre></td></tr></table></figure>

<p>环境装好了，开始测试项目：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Compile protos.生成proto文件，一个py文件对应生成一个proto文件</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br><span class="line"># Install TensorFlow Object Detection API.</span><br><span class="line">cp object_detection/packages/tf2/setup.py .</span><br><span class="line">python -m pip install --use-feature=2020-resolver .</span><br><span class="line">#发现这一步会将上一步安装的三个版本的插件又改回去，还会安装tensorflow2.6.0，然后运行下一步报错：没有resnet50，gg</span><br><span class="line"></span><br><span class="line"># Test the installation.</span><br><span class="line">python object_detection/builders/model_builder_tf2_test.py</span><br></pre></td></tr></table></figure>

<p>于是重装上面三个插件（版本），卸载tensorflow2.6，安装tensorflow2.2（conda库里没有就用pip装）</p>
<p>只有gpu没有cpu的会报错： No module named ‘tensorflow.compat’</p>
<p>再次报错： cannot import name ‘resnet50’，gg</p>
<p>然后发现是环境变量没换</p>
<p>这里我用两个环境变量：</p>
<p>PATH里</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818212837624.png" alt="image-20210818212837624"></p>
<p>PYTHONPATH里：</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818212917529.png" alt="image-20210818212917529"></p>
<p>用哪个把那个放上面就行了</p>
<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/builders/model_builder_tf2_test.py</span><br></pre></td></tr></table></figure>

<p>报错：</p>
<p>from official.vision.image_classification.efficientnet import efficientnet_model<br>ModuleNotFoundError: No module named ‘official’</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/63460911/why-do-i-keep-on-getting-no-module-named-official-error">https://stackoverflow.com/questions/63460911/why-do-i-keep-on-getting-no-module-named-official-error</a></p>
<p>这篇文章说：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(ob) D:\code\object detection2.0&gt;cd models</span><br><span class="line"></span><br><span class="line">(ob) D:\code\object detection2.0\models&gt;cd research</span><br><span class="line"></span><br><span class="line">(ob) D:\code\object detection2.0\models\research&gt;pip install tf-models-official</span><br></pre></td></tr></table></figure>

<p>然后又给我换成2.6.0了</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818223551339.png" alt="image-20210818223551339"></p>
<p>运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/builders/model_builder_tf2_test.py</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818223716643.png" alt="image-20210818223716643"></p>
<p>再次怀疑是cuda版本的问题</p>
<p>去下载cuda11.1.0和对应版本的cudnn</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1qh411Y7uX?from=search&amp;seid=4131547032775557021">https://www.bilibili.com/video/BV1qh411Y7uX?from=search&amp;seid=4131547032775557021</a></p>
<p>安装cudatoolkit和cudnn</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818230115971.png" alt="image-20210818230115971"></p>
<p>再次运行报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">: F .\tensorflow/core/kernels/random_op_gpu.h:246] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch&lt;Distribution&gt;, num_blocks, block_size, 0, d.stream(), key, counter, gen, data, size, dist) status:</span><br><span class="line"> Internal: invalid configuration argument</span><br><span class="line">Fatal Python error: Aborted</span><br></pre></td></tr></table></figure>

<p>在py文件中添加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">os.environ[&quot;CUDA_DEVICE_ORDER&quot;] = &quot;PCI_BUS_ID&quot;</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;5&quot;</span><br><span class="line">gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.83)</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))</span><br></pre></td></tr></table></figure>

<p>解决</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210821123855565.png" alt="image-20210821123855565"></p>
<h2 id="版本不符"><a href="#版本不符" class="headerlink" title="版本不符"></a>版本不符</h2><p>百度说tensorflow和cuda版本不符：</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210818235538040.png" alt="image-20210818235538040"></p>
<p>于是 下载</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-gpu==2.4</span><br></pre></td></tr></table></figure>

<p>但是又卸载了一些2.6的东西</p>
<p>先不运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp object_detection/packages/tf2/setup.py .</span><br><span class="line">python -m pip install --use-feature=2020-resolver .</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/builders/model_builder_tf2_test.py</span><br></pre></td></tr></table></figure>

<p>报错</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> from tensorflow.python.keras.layers.normalization import LayerNormalization</span><br><span class="line">ImportError: cannot import name &#x27;LayerNormalization&#x27;</span><br></pre></td></tr></table></figure>

<p>再运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp object_detection/packages/tf2/setup.py .</span><br><span class="line">python -m pip install --use-feature=2020-resolver .</span><br></pre></td></tr></table></figure>

<p>还是报一样的错</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/68080345/importerror-cannot-import-name-layernormalization-from-tensorflow-python-ker">https://stackoverflow.com/questions/68080345/importerror-cannot-import-name-layernormalization-from-tensorflow-python-ker</a></p>
<p>这篇文章说将tensorflow降级到2.3.0，但是这样就不符合cuda版本了</p>
<p>最后删除2.6.0的cpu，安装2.4的cpu版</p>
<p>报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch&lt;Distribution&gt;, num_blocks, block_size, 0, d.stream(), key, counter, gen, data, size, dist) status:</span><br><span class="line"> Internal: invalid configuration argument</span><br><span class="line">Fatal Python error: Aborted</span><br></pre></td></tr></table></figure>

<p>算了还是用网上的测试代码吧，tensorflow2.0版本测试gpu代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow.compat.v1 as tf</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">a = tf.constant(1)</span><br><span class="line">b = tf.constant(1)</span><br><span class="line">c = a + b</span><br><span class="line">sess = tf.Session(config =tf.ConfigProto(log_device_placement = True))</span><br><span class="line">print(sess.run(c))</span><br></pre></td></tr></table></figure>

<p>成功输出：2</p>
<p>使用tf2来训练：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/model_main_tf2.py --pipeline_config_path=training_my/ssdlite_mobilenet_v2_coco.config --model_dir=training_my --alsologtostderr</span><br></pre></td></tr></table></figure>

<p>报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">   compat.path_to_str(self.__name), 1024 * 512)</span><br><span class="line">UnicodeDecodeError: &#x27;utf-8&#x27; codec can&#x27;t decode byte 0xd5 in position 94: invalid continuation byte</span><br></pre></td></tr></table></figure>

<p>怀疑是tfrecord文件编码格式不对，找到了另外一个人生成tfrecord文件的代码</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zong596568821xp/article/details/82015126">https://blog.csdn.net/zong596568821xp/article/details/82015126</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python generate_tfrecord.py --csv_input=../train.csv --output_path=../data/train.record</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=../test.csv --output_path=../data/test.record</span><br></pre></td></tr></table></figure>

<p>结果报错</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> File &quot;E:\Anaconda3-\machinelearning\envs\ob\lib\site-packages\tensorflow\python\lib\io\file_io.py&quot;, line 80, in _preread_check</span><br><span class="line">    compat.path_to_str(self.__name), 1024 * 512)</span><br><span class="line">UnicodeDecodeError: &#x27;utf-8&#x27; codec can&#x27;t decode byte 0xd5 in position 57: invalid continuation byte</span><br></pre></td></tr></table></figure>

<p>和上面一样</p>
<p>执行setup.py，装回2.6</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install --use-feature=2020-resolver .</span><br><span class="line"></span><br><span class="line">python object_detection/model_main_tf2.py --pipeline_config_path=training_my/ssdlite_mobilenet_v2_coco.config --model_dir=training_my --alsologtostderr</span><br></pre></td></tr></table></figure>

<p>报错</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> File &quot;E:\Anaconda3-\machinelearning\envs\ob\lib\site-packages\tensorflow\python\lib\io\file_io.py&quot;, line 80, in _preread_check</span><br><span class="line">    compat.path_to_str(self.__name), 1024 * 512)</span><br><span class="line">UnicodeDecodeError: &#x27;utf-8&#x27; codec can&#x27;t decode byte 0xd5 in position 94: invalid continuation byte</span><br></pre></td></tr></table></figure>

<p>发现record文件是ansi编码</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210821111959296.png" alt="image-20210821111959296"></p>
<p>我敲</p>
<p><img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210821142435913.png" alt="image-20210821142435913"></p>
<p>马上改：但是window不让改，改完马上又便会utf-8，知乎上说ansi不是一种编码格式，win10上的ansi就是utf-8。</p>
<p>将training_my文件夹改成training</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/model_main_tf2.py --pipeline_config_path=training/ssdlite_mobilenet_v2_coco.config --model_dir=training --alsologtostderr</span><br><span class="line">python object_detection/model_main_tf2.py --pipeline_config_path=training/ssdlite_mobilenet_v2_coco.config --model_dir=training/model --checkpoint_dir=traing/checkpoint --alsologtostderr</span><br></pre></td></tr></table></figure>

<p>这位老哥的问题和我一样</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/67426245/unicodedecodeerror-utf-8-codec-cant-decode-byte-0xd5-in-position-93-invalid">https://stackoverflow.com/questions/67426245/unicodedecodeerror-utf-8-codec-cant-decode-byte-0xd5-in-position-93-invalid</a></p>
<p>又找到了一个倒霉蛋：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40493501/article/details/89787144%EF%BC%88%E6%97%A0%E8%A7%A3%E5%86%B3%EF%BC%89">https://blog.csdn.net/weixin_40493501/article/details/89787144（无解决）</a></p>
<h1 id="再次remake"><a href="#再次remake" class="headerlink" title="再次remake"></a>再次remake</h1><p>跟着这个视屏来做：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1tW411T7ei?p=2">https://www.bilibili.com/video/BV1tW411T7ei?p=2</a></p>
<ol>
<li><p>&#96;&#96;&#96;<br>#安装tf1.14.0</p>
<p>(tf&#x3D;pose) D:\code\ob3.0&gt;pip install tensorflow&#x3D;&#x3D;1.14.0</p>
<p>#先不安装gpu</p>
<p>#搭建环境<br>cp object_detection&#x2F;packages&#x2F;tf1&#x2F;setup.py .<br>python -m pip install –use-feature&#x3D;2020-resolver .</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">最终将train放在和research目录下，和object_detection同级：(报错)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p> ‘Tensorflow’.format(feature_extractor_type))</p>
</li>
</ol>
<p>ValueError: ssd_mobilenet_v2 is not supported. See <code>model_builder.py</code> for features extractors compatible with different versions of Tensorflow</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">改模型不支持tensorflow2，</span><br><span class="line"></span><br><span class="line"># 重新搞tensorflow1.x</span><br><span class="line"></span><br><span class="line">activate tf-pose</span><br><span class="line"></span><br><span class="line">我们换回目标检测项目，环境变量也换了，安装cuda10，</span><br><span class="line"></span><br><span class="line">cudnn：https://developer.nvidia.com/rdp/cudnn-archive#a-collapse765-10</span><br><span class="line"></span><br><span class="line">cuda：https://developer.nvidia.com/cuda-toolkit-archive</span><br><span class="line"></span><br><span class="line">cuda只安装这四个：</span><br><span class="line"></span><br><span class="line">![image-20210824115302952](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824115302952.png)</span><br><span class="line"></span><br><span class="line">![image-20210824115412219](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824115412219.png)</span><br><span class="line"></span><br><span class="line">现在好像不用下载cudnn了这里面点不进去</span><br><span class="line"></span><br><span class="line">直接就有cudnn文件夹，将其打开，把里面的三个文件夹复制到外面就行了：</span><br><span class="line"></span><br><span class="line">![image-20210824120626739](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824120626739.png)</span><br><span class="line"></span><br><span class="line">复制过去，完成</span><br><span class="line"></span><br><span class="line">![image-20210824120749298](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824120749298.png)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;.&#x2F;training_my&#x2F;ssdlite_mobilenet_v2_coco.config –model_dir&#x3D;.&#x2F;training_my –alsologtostderr</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">回到原来的问题：没有使用gpu</span><br><span class="line"></span><br><span class="line">![image-20210824121551465](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824121551465.png)</span><br><span class="line"></span><br><span class="line">安装tensorflow1.15后</span><br><span class="line"></span><br><span class="line">测试是否成功</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;builders&#x2F;model_builder_tf1_test.py<br>#报错：<br>ImportError: cannot import name ‘resnet50’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">安装会1.14，问题消失</span><br><span class="line"></span><br><span class="line">但是还是用的cpu</span><br><span class="line"></span><br><span class="line">![image-20210824131641749](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824131641749.png)</span><br><span class="line"></span><br><span class="line">发现问题：需要7.4的cudnn而我的是cudnn7.6：</span><br><span class="line">![image-20210824131739883](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824131739883.png)</span><br><span class="line"></span><br><span class="line">去下载cudnn7.4：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>nvidia-smi</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20210824132935567](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824132935567.png)</span><br><span class="line"></span><br><span class="line">最终将上面的改成下面的成功使用gpu了</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>import os</p>
<h1 id="os-environ-‘CUDA-VISIBLE-DEVICES’-x3D-‘-x2F-device-GPU-0’"><a href="#os-environ-‘CUDA-VISIBLE-DEVICES’-x3D-‘-x2F-device-GPU-0’" class="headerlink" title="os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; ‘&#x2F;device:GPU:0’"></a>os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; ‘&#x2F;device:GPU:0’</h1><p>os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; “0”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">虽然任务管理器中没有使用，但是我相信联想电脑管家</span><br><span class="line"></span><br><span class="line">![image-20210824154807005](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824154807005.png)</span><br><span class="line"></span><br><span class="line">![image-20210824154752154](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824154752154.png)</span><br><span class="line"></span><br><span class="line">20%是因为：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>gpu_options &#x3D; tf.GPUOptions(per_process_gpu_memory_fraction&#x3D;0.2)#0.9表示可以使用GPU 90%的资源进行训练，可以任意修改</p>
<p>sess &#x3D; tf.Session(config&#x3D;tf.ConfigProto(gpu_options&#x3D;gpu_options))</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">改成0.7</span><br><span class="line"></span><br><span class="line">不能修改train_my为train文件夹</span><br><span class="line"></span><br><span class="line"># 测试：</span><br><span class="line"></span><br><span class="line">## 导出模型命令</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;export_inference_graph.py –input_type&#x3D;image_tensor –pipeline_config_path&#x3D;training_my&#x2F;ssdlite_mobilenet_v2_coco.config –trained_checkpoint_prefix&#x3D;training_my&#x2F;model.ckpt-9000 –output_directory&#x3D;window_inference_graph</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">使用select_images文件夹中的图片，在图片中随机选取十张来测验：</span><br><span class="line"></span><br><span class="line">![image-20210824183256102](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824183256102.png)</span><br><span class="line"></span><br><span class="line">运行test_my_model.py</span><br><span class="line"></span><br><span class="line">一定要将matplotlib放在最后倒入，不然会出问题</span><br><span class="line"></span><br><span class="line">成昆：</span><br><span class="line"></span><br><span class="line">![image-20210824184908267](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824184908267.png)</span><br><span class="line"></span><br><span class="line">让原本部署到树莓派的程序使用本模型：</span><br><span class="line"></span><br><span class="line">报错：</span><br><span class="line"></span><br><span class="line">from object_detection.protos import string_int_label_map_pb2</span><br><span class="line">ImportError: cannot import name ‘string_int_label_map_pb2’</span><br><span class="line"></span><br><span class="line">网上都说是在说protos文件夹没有这个文件</span><br><span class="line"></span><br><span class="line">但是</span><br><span class="line"></span><br><span class="line">![image-20210824191540441](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824191540441.png)</span><br><span class="line"></span><br><span class="line">也不行</span><br><span class="line"></span><br><span class="line">https://stackoverflow.com/questions/60999011/importerror-cannot-import-name-string-int-label-map-pb2-on-windows</span><br><span class="line"></span><br><span class="line">这个人和我问题一样</span><br><span class="line"></span><br><span class="line">![image-20210824192602444](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824192602444.png)</span><br><span class="line"></span><br><span class="line">原来我以前也遇到过这个问题，这就是不记笔记的傻逼的下场，</span><br><span class="line"></span><br><span class="line">。。。不对啊，之前能跑就说明这个东西是没问题的啊，啥也没改就突然有问题了？寄了</span><br><span class="line"></span><br><span class="line">原来我是直接将该文件放在utils文件夹下，然后直接import</span><br><span class="line"></span><br><span class="line">![image-20210824193315371](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210824193315371.png)</span><br><span class="line"></span><br><span class="line">绝了，</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>pip install urllib3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">完成：能成功检测了，但是正确率非常低，一直都会有window出现</span><br><span class="line"></span><br><span class="line">发现原来这两行是预训练模型的位置</span><br><span class="line"></span><br><span class="line">![image-20210825001231312](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210825001231312.png)</span><br><span class="line"></span><br><span class="line">我靠，我之前删掉了，难怪这么低</span><br><span class="line"></span><br><span class="line"># coco数据集整理</span><br><span class="line"></span><br><span class="line">1. 下载coco数据集：文件结构如下：（person_keypoints是人体结构的标注）</span><br><span class="line"></span><br><span class="line">![image-20210825220723003](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210825220723003.png)</span><br><span class="line"></span><br><span class="line">1. 将coco数据集的instance.json提取出来，转换为xml文件</span><br><span class="line"></span><br><span class="line">2. 将xml对应的图片拿出来和xml文件放在一起</span><br><span class="line"></span><br><span class="line">   ![image-20210825223314606](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210825223314606.png)</span><br><span class="line"></span><br><span class="line">3. 将一步的train文件和n04589890合并到imgs_xml文件夹(之后就是重复之前的步骤了)</span><br><span class="line"></span><br><span class="line">4. 用xml_to_csv.py和csv_to_tfrecord.py生成tfrecord文件</span><br><span class="line"></span><br><span class="line">5. 编辑my_label_map.pbtxt和ssdlite_mobilenet_v2_coco.config文件</span><br><span class="line"></span><br><span class="line">6. 训练，使用（估计要训练一年）</span><br><span class="line"></span><br><span class="line">发现问题：n04589890这个文件夹里的xml文件中的是n04589890，而不是window，需要换掉</span><br><span class="line"></span><br><span class="line">修改此处：</span><br><span class="line"></span><br><span class="line">![image-20210826102651880](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826102651880.png)</span><br><span class="line"></span><br><span class="line">![image-20210826103140941](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826103140941.png)</span><br><span class="line"></span><br><span class="line">打印出来才发现</span><br><span class="line"></span><br><span class="line">![image-20210826103154570](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826103154570.png)</span><br><span class="line"></span><br><span class="line">改成</span><br><span class="line"></span><br><span class="line">运行csv_to_tfrecord的时候发现不能使用JPEG格式，于是，使用jpeg_to_jpg.py （直接运行）让将n04589890里的图片以jpg格式保存到imgs_xml中</span><br><span class="line"></span><br><span class="line">再次运行csv_to_tfrecord</span><br><span class="line"></span><br><span class="line">玩毛，还是报一样的错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>with open(image_path, ‘rb’) as file:<br>FileNotFoundError: [Errno 2] No such file or directory: ‘imgs_xml\n04589890_10327’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">print一下image_path:</span><br><span class="line"></span><br><span class="line">![image-20210826110956289](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826110956289.png)</span><br><span class="line"></span><br><span class="line">打开csv文件：</span><br><span class="line"></span><br><span class="line">![image-20210826120347139](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826120347139.png)</span><br><span class="line"></span><br><span class="line">发现这里就没有.jpg</span><br><span class="line"></span><br><span class="line">![image-20210826151925235](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826151925235.png)</span><br><span class="line"></span><br><span class="line">在生成csv的py文件中添加如上代码，运行</span><br><span class="line"></span><br><span class="line">成功生成</span><br><span class="line"></span><br><span class="line"># 训练：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training_my –alsologtostderr</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>label_map.ParseFromString(label_map_string)<br>TypeError: a bytes-like object is required, not ‘str’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20210826154435740](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826154435740.png)</span><br><span class="line"></span><br><span class="line">原来是这里用成了中文的引号</span><br><span class="line"></span><br><span class="line">再次运行，报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>File “D:\code\目标检测\models\research\object_detection\eval_util.py”, line 1098, in get_evaluators<br>    raise ValueError(‘Metric not found: {}’.format(eval_metric_fn_key))<br>ValueError: Metric not found: open_images_V2_detection_metrics</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20210826161021087](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826161021087.png)</span><br><span class="line"></span><br><span class="line">看样子应该是没有这个文件，感觉最近运气有点好（有进度的感觉好好）</span><br><span class="line"></span><br><span class="line">换成：`oid_V2_detection_metrics`</span><br><span class="line"></span><br><span class="line">每次运行都会卡在这里</span><br><span class="line"></span><br><span class="line">![image-20210826182217305](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826182217305.png)</span><br><span class="line"></span><br><span class="line">这个人的问题和我一样</span><br><span class="line"></span><br><span class="line">https://stackoverflow.com/questions/59609378/tensorflow-object-detection-api-training-fails-silently（无解决）</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/u010122972/article/details/77387429</span><br><span class="line"></span><br><span class="line">这句话的意思是，将下面这行移出，让评估无期限得进行下去（哪路或多）</span><br><span class="line"></span><br><span class="line">![image-20210826185139808](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210826185139808.png)</span><br><span class="line"></span><br><span class="line">加上</span><br><span class="line"></span><br><span class="line">使用fast_rcnn:</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;faster_rcnn_inception_resnet_v2_atrous_oid_v4.config –model_dir&#x3D;training_my –alsologtostderr</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">会报错，无法运行</span><br><span class="line"></span><br><span class="line">用回oid：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training_my –alsologtostderr</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">还是卡在</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>I0829 22:08:23.212716 33152 session_manager.py:502] Done running local_init_</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20210829224419128](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210829224419128.png)</span><br><span class="line"></span><br><span class="line">突然想到是不是我训练集的图片太多了导致的？</span><br><span class="line"></span><br><span class="line">![image-20210829224558772](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210829224558772.png)</span><br><span class="line"></span><br><span class="line">coco数据集里的训练集只有两千张，imgnet的数据集不多，所以应该也差不多三千罢了</span><br><span class="line"></span><br><span class="line">![image-20210829225555627](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210829225555627.png)</span><br><span class="line"></span><br><span class="line">将这里修改，为0.01,原本为0.1，所以测试图片也该变为六百多张</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/qq_28019591/article/details/86560116</span><br><span class="line"></span><br><span class="line">![image-20210829232927010](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210829232927010.png)</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/qq_37541097/article/details/101711261</span><br><span class="line"></span><br><span class="line">![image-20210829233941134](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210829233941134.png)</span><br><span class="line"></span><br><span class="line">原来如此：</span><br><span class="line"></span><br><span class="line">对config文件做如下修改：</span><br><span class="line"></span><br><span class="line">![image-20210830000156870](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830000156870.png)</span><br><span class="line"></span><br><span class="line">会报错</span><br><span class="line"></span><br><span class="line">![image-20210830000425045](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830000425045.png)</span><br><span class="line"></span><br><span class="line">改回去</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training_my –sample_1_of_n_eval_examples&#x3D;25 –alsologtostderr </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">有用：只卡了几分钟了</span><br><span class="line"></span><br><span class="line">![image-20210830003000559](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830003000559.png)</span><br><span class="line"></span><br><span class="line">然而效果很差，打开一看模型只有50M（原模型有190M）</span><br><span class="line"></span><br><span class="line">![image-20210830164234903](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830164234903.png)</span><br><span class="line"></span><br><span class="line">没有一张检测出来，gg，回到解放前</span><br><span class="line"></span><br><span class="line">几把炸裂</span><br><span class="line"></span><br><span class="line">## 怎么办？</span><br><span class="line"></span><br><span class="line">### 分析问题原因：</span><br><span class="line"></span><br><span class="line">1. 没有使用原来的模型，路径出错了</span><br><span class="line"></span><br><span class="line">![image-20210830165242041](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830165242041.png)</span><br><span class="line"></span><br><span class="line">1. 模型效果本身就不好（也不太可能）</span><br><span class="line">2. 训练step不够：</span><br><span class="line">   - 做如下修改</span><br><span class="line">   - ![image-20210830165615824](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830165615824.png)</span><br><span class="line">   - 训练到五万个batch，效果还是无法看</span><br><span class="line">   - </span><br><span class="line">   - </span><br><span class="line"></span><br><span class="line">3. 是评估的图片太少导致训练效果不好（不太可能，那个人用100张图片训练出来的照样可以检测）</span><br><span class="line">4. 人和窗户图片数量相差太多导致训练效果不好</span><br><span class="line"></span><br><span class="line">**将模型保存设置为十万个steps保存一次**</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/natures66/article/details/106080898</span><br><span class="line"></span><br><span class="line">根据这篇文章</span><br><span class="line"></span><br><span class="line">![image-20210831163456211](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210831163456211.png)</span><br><span class="line"></span><br><span class="line">还是不行，这样每次训练就得两小时起步了，还是改回十分钟保存一次吧</span><br><span class="line"></span><br><span class="line">1. 图片size不一致导致定位不准：</span><br><span class="line"></span><br><span class="line">   ![image-20210902163430577](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210902163430577.png)</span><br><span class="line"></span><br><span class="line">   不是这个问题，每个图片使用的都是自己的width，height</span><br><span class="line"></span><br><span class="line">2. 发现问题：coco数据集里的人都是多个人的，而xml_to_csv.py都是使用的第一个object</span><br><span class="line"></span><br><span class="line">   发现上面的xmin_list使用的是list，所以这个cvs_to_tfrecord.py 其实是支持一张图片中有多个人的，只是xml_to_csv.py没有把多个人存入csv中，所以</span><br><span class="line"></span><br><span class="line">   我们对xml_to_csv.py做如下修改：</span><br><span class="line"></span><br><span class="line">   乌龙：其实不需要修改</span><br><span class="line"></span><br><span class="line">   ![image-20210902171434761](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210902171434761.png)</span><br><span class="line"></span><br><span class="line">   这个东西每张图片的人都能检测到。误会解除</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>   image_resizer {<br>         fixed_shape_resizer {<br>           height: 300<br>           width: 300<br>         }<br>       }<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   好像并没有解除，这是config文件里的（意义不明）</span><br><span class="line"></span><br><span class="line">   https://blog.csdn.net/l13022736018/article/details/108619875根据这篇文章，(暂时搁置)</span><br><span class="line"></span><br><span class="line">3. 今天睡午觉的时候突然想到会不会是学习率和训练batch_steps不匹配导致训练效果很差，比如这个配置文件里的学习率就是要到一千万个batch才有效果</span><br><span class="line"></span><br><span class="line">   解决办法：</span><br><span class="line"></span><br><span class="line">   - https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md</span><br><span class="line">   - 复制ssd_coco_v2的链接，再打开迅雷，会自动下载</span><br><span class="line">   - 解压到object_detection目录下再解压</span><br><span class="line">   - 复制sample/configs/里对应的config文件到train_my目录下修改对应record路径和模型路径和num_class</span><br><span class="line">   - 运行</span><br><span class="line">   - `python object_detection/model_main.py --pipeline_config_path=training_my/ssd_mobilenet_v2_coco.config --model_dir=training_my --sample_1_of_n_eval_examples=25 --alsologtostderr    -    开始运行孩童检测生成步骤同上运行```shellpython object_detection/model_main.py --pipeline_config_path=training/ssd_mobilenet_v2_coco.config --model_dir=training  --alsologtostderr     `</span><br><span class="line"></span><br><span class="line"># 视频传输</span><br><span class="line"></span><br><span class="line">**使用python进行将摄像头捕获到的视频传输到云服务器上**</span><br><span class="line"></span><br><span class="line">[https://blog.csdn.net/qq_42722197/article/details/109665279?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link](https://blog.csdn.net/qq_42722197/article/details/109665279?utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-3.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-3.no_search_link)</span><br><span class="line"></span><br><span class="line">根据这篇文章，</span><br><span class="line"></span><br><span class="line">先克隆下来：`https://github.com/NakulLakhotia/Live-Streaming-using-OpenCV-Flask`</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>pip install flask<br>#报错，can&#96;t import ContextVar，csdn说版本太高了<br>pip install flask&#x3D;&#x3D;1.0 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">运行app.py</span><br><span class="line"></span><br><span class="line">在本机5000 端口查看，成功显示摄像头</span><br><span class="line"></span><br><span class="line">然而这是需要前端请求然后才能开启摄像头，我们需要的是在一直拍摄中将数据一直传到服务器</span><br><span class="line"></span><br><span class="line">[https://www.cnblogs.com/syy1757528181/p/14333286.html，这篇文章非常详细，https://blog.csdn.net/huhumama0/article/details/9164873?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link](https://www.cnblogs.com/syy1757528181/p/14333286.html，这篇文章非常详细，https://blog.csdn.net/huhumama0/article/details/9164873?utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link)</span><br><span class="line"></span><br><span class="line">然后发现小组成员使用了frp这个工具来进行视频传输，也就是说从树莓派到服务器，到手机的视屏传输都是这个东西在负责，也就是说如果不用这个东西了，就需要自己写服务器接受数据再传到安卓手机的代码，工作量是一个未知数。</span><br><span class="line"></span><br><span class="line">现有两种办法：</span><br><span class="line"></span><br><span class="line">1. 使用代码将数据封装成原来frp树莓派端发送数据的格式</span><br><span class="line"></span><br><span class="line">   需要：查看frp源代码，找出封装数据的格式</span><br><span class="line"></span><br><span class="line">2. 在localtion.py中调用frp的树莓派端的程序。然后在frp程序调用摄像头之前，将摄像头资源变为全局变量。</span><br><span class="line"></span><br><span class="line">这个内网穿透工具的意思是，你请求服务器加端口地址，服务器将请求转发给树莓派，然后树莓派将视屏发给浏览器（或者服务器，这个无所谓了，知道前面的流程就行了）</span><br><span class="line"></span><br><span class="line">也就是说第一个办法直接作废，因为这是一个被动的过程。（好像也不是作废，算了还是搞第二种吧）</span><br><span class="line"></span><br><span class="line">https://www.cnblogs.com/mulanhao/p/15167562.html，根据这篇文章，这个只是个传数据的方式，根本没有调用摄像头</span><br><span class="line"></span><br><span class="line">还是得用motion：motion就是提供局域网内实时监控的的工具，结合上面的内网穿透工具，就相当于将浏览器和树莓派置于同一网段下了，所以可以使用motion监控</span><br><span class="line"></span><br><span class="line">github：https://github.com/sackmotion/motion</span><br><span class="line"></span><br><span class="line">现在又两种办法：</span><br><span class="line"></span><br><span class="line">1. 将在调用motion的时候用python将摄像头资源提取出来</span><br><span class="line">2. 在树莓派上使用127.0.0.1：8181获得motion传过来的数据</span><br><span class="line"></span><br><span class="line">显然后者比较靠谱，前者相当于提取一个进程正在使用的资源（但是如果是在这个进程开启之前通共享）</span><br><span class="line"></span><br><span class="line">https://www.cnblogs.com/Yunrui-blogs/p/12690080.html，这个人提供了查看树莓派被摄像头状态的</span><br><span class="line"></span><br><span class="line">好像cv2capture(url)可以直接获取网络摄像头的数据，不过不知道motion提供的是不是网络摄像头（看性质完全符合）</span><br><span class="line"></span><br><span class="line">**成功**</span><br><span class="line"></span><br><span class="line">## 启动motion命令：</span><br><span class="line"></span><br><span class="line">root权限下,/home/motion目录下：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>service motion start<br>motion</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">浏览器请求端口：8081</span><br><span class="line"></span><br><span class="line">然后是不打开摄像头的情况下使用：（注释掉这些就行了）</span><br><span class="line"></span><br><span class="line">![image-20210907191535871](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210907191535871.png)</span><br><span class="line"></span><br><span class="line">这个红框中的if是和while true在同一级下的，所以没了这个，就没有了跳出while的手段，所以会一直检测下去，不能释放</span><br><span class="line"></span><br><span class="line">if里面的句子意思是如果这张图片显示了25毫秒，并且有人按了‘q’就退出程序</span><br><span class="line"></span><br><span class="line">所以我们修改成这样</span><br><span class="line"></span><br><span class="line">![image-20210907202234153](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210907202234153.png)</span><br><span class="line"></span><br><span class="line">就能在树莓派上不开显示器使用模型进行检测了，还是‘q’退出</span><br><span class="line"></span><br><span class="line"># 检测</span><br><span class="line"></span><br><span class="line">在b站上爬了一个儿童爬窗户的视频</span><br><span class="line"></span><br><span class="line">先使用官方模型进行检测</span><br><span class="line"></span><br><span class="line">video_detection.py(要修改的东西就在第一段)</span><br><span class="line"></span><br><span class="line">但是编码格式报错，我使用的是flv文件</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/u013913216/article/details/82144395</span><br><span class="line"></span><br><span class="line">这篇文章说应该</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>fourcc &#x3D; cv2.VideoWriter_fourcc(‘F’, ‘L’, ‘V’, ‘1’)   </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这样</span><br><span class="line"></span><br><span class="line">还是报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>OpenCV: FFMPEG: tag 0x31564c46&#x2F;‘FLV1’ is not supported with codec id 21 and format ‘flv &#x2F; FLV (Flash Video)’<br>OpenCV: FFMPEG: fallback to use tag 0x00000002&#x2F;‘????’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">但是上面有一个运行时间，所以这是运行完才报的错，一看成功生成了对应视频文件。**成昆**</span><br><span class="line"></span><br><span class="line">发现一个问题，人的检测效果非常好（即使使用person也能轻松检测出小孩子），窗户的检测效果很差</span><br><span class="line"></span><br><span class="line">让我们不得不重新考虑使用成年和窗户的数据来训练。如果使用孩子的数据集检测效果不好，那就只能使用成年人的了</span><br><span class="line"></span><br><span class="line">运行到十万之后，小孩数据集训练的模型效果很差，反而五万的成人数据集能轻松检测出小孩的身体。（remake，看来是数据集的问题）我让同小组的来训练成人的，我继续训练孩童的，没必要训练完，也许二十万效果就会很好了。但是合作很不愉快，配合得并不是很好。</span><br><span class="line"></span><br><span class="line">使用来检测窗户：</span><br><span class="line"></span><br><span class="line">![image-20210912164156219](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210912164156219.png)</span><br><span class="line"></span><br><span class="line">效果非常好，但是有个问题，并不能很好地检测出训练集里面的窗户（里面的窗户非常不规整，不是这种四四方方的），但是考虑到实际情况也是像图片里这种将摄像头正对着窗户的。所以也无需考虑。</span><br><span class="line"></span><br><span class="line">目前为止，可以说是基本完工了，上学期就和同一小组成员计划好了，先弄这个简单的目标检测来保底，然后尝试用tf-posenet来实现动作检测。所以这里让另外一位worker去尝试。</span><br><span class="line"></span><br><span class="line">刚刚洗澡的时候突然回忆起，coco数据集中人体关节的标签，于是有下面的推测：动作检测并不是检测一定帧的图片，而是仍然检测一张图片，根据图中关节的位置来做判断。如此就跟目标检测差不多了。看看期中后有没有时间来做吧</span><br><span class="line"></span><br><span class="line">刚刚洗内裤的时候突然想起，不同的项目api不同检测的时候掉两遍api，使用两次视频流是个需要解决的问题（不知道怎么做）。但是现在想到其实可以用掉两次motion的网络视频，运行两个程序，当两个程序都发出报警信号的时候才视为危险（一种方法是修改服务器的接受信号变量，增加一个危险信号2，当两个危险信号都为true的时候才报警（有点麻烦，需要让另一个同学动刀）。另一种方法树莓派内部传递信号，将目标检测程序的危险信号发给动作检测程序（还不知道怎么做））</span><br><span class="line"></span><br><span class="line"># 设计开机自启动</span><br><span class="line"></span><br><span class="line">以后再也不用去另一栋楼里了</span><br><span class="line"></span><br><span class="line">根据这篇文章</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/qq_38960682/article/details/80259321</span><br><span class="line"></span><br><span class="line">简简单单，希望不要出问题</span><br><span class="line"></span><br><span class="line">编写这两个文件，然后复制到/home/pi/.config/autostart</span><br><span class="line"></span><br><span class="line">![image-20210914232434476](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210914232434476.png)</span><br><span class="line"></span><br><span class="line">重启树莓派即可</span><br><span class="line"></span><br><span class="line">失败，又找了很多文章，说要改什么etc/rc.local文件，还是没用</span><br><span class="line"></span><br><span class="line">算了还是吧命令给组长，让组长每次自己启动吧</span><br><span class="line"></span><br><span class="line"># 整合docker</span><br><span class="line"></span><br><span class="line">## 安装yum</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>apt install yum</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">报错：</span><br><span class="line"></span><br><span class="line">apt install yum E: 无法获得锁 /var/lib/dpkg/lock - open (11: 资源暂时不可用)</span><br><span class="line"></span><br><span class="line">不是root的问题，</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/qq_42272783/article/details/102666528</span><br><span class="line"></span><br><span class="line">使用这篇文章中暴力破解法（解决）</span><br><span class="line"></span><br><span class="line">## 安装Docker</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>apt  install docker.io</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 官网下载：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="From-the-root-of-the-git-repository"><a href="#From-the-root-of-the-git-repository" class="headerlink" title="From the root of the git repository"></a>From the root of the git repository</h1><p>docker build -f research&#x2F;object_detection&#x2F;dockerfiles&#x2F;tf1&#x2F;Dockerfile -t od .<br>docker run -it od</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20210830195137522](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20210830195137522.png)</span><br><span class="line"></span><br><span class="line">卡在这里半个小时</span><br><span class="line"></span><br><span class="line">将官网的复制dockerfile复制下来粘贴到本地：</span><br><span class="line"></span><br><span class="line">并没有什么乱用，暂时放弃</span><br><span class="line"></span><br><span class="line">## 环境搭建</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>conda info -e</p>
<p>conda create -n tf-pose python&#x3D;3.6</p>
<p>source activate<br>conda activate tf-pose<br>cd models&#x2F;research</p>
<h1 id="Compile-protos"><a href="#Compile-protos" class="headerlink" title="Compile protos."></a>Compile protos.</h1><p>protoc object_detection&#x2F;protos&#x2F;*.proto –python_out&#x3D;.</p>
<h1 id="Install-TensorFlow-Object-Detection-API"><a href="#Install-TensorFlow-Object-Detection-API" class="headerlink" title="Install TensorFlow Object Detection API."></a>Install TensorFlow Object Detection API.</h1><p>cp object_detection&#x2F;packages&#x2F;tf1&#x2F;setup.py .<br>python -m pip install –use-feature&#x3D;2020-resolver .</p>
<p>python object_detection&#x2F;builders&#x2F;model_builder_tf1_test.py</p>
<p>#如果出现no module named official错误</p>
<p>1PYTHONPATH&#x3D;path\to\models</p>
<p>cd models</p>
<p>执行 export PYTHONPATH&#x3D;$PYTHONPATH:<code>pwd</code>:<code>pwd</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 总结</span><br><span class="line"></span><br><span class="line">（上学期就只用了官网的模型）八月十七号开始搞，九月十六号晚上结束。第一周基本上是除了睡觉吃饭洗澡，就在搞这个（速度很慢，很多问题），第二周开始普通工作时间来搞（一个问题卡了快一周，心态发生了变化），第三周基本就是改进（包括换数据集，测试使用docker，测试视频等等），最后这一周就是去上课，吃饭的时候，让电脑自己训练。</span><br><span class="line"></span><br><span class="line">work的时候写这样一篇杂记是非常重要的，特别是什么都不知道的情况下（其实即使精通了也该写，只不过写得少一点）。在你用**控制变量法**做实验的时候，如果没有把自己之前做过的事写下来，很有可能因为忘了做没做而又需要再做一遍。如果有这样一篇杂记，就能`ctrl+f`一下就行了。</span><br><span class="line"></span><br><span class="line"># 再就业</span><br><span class="line"></span><br><span class="line">需求，神偷鬼墨地使用官方的检测b栈下载的视屏中的小孩子和窗子：</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/qq_33507306/article/details/92847413</span><br><span class="line"></span><br><span class="line">根据这篇文章将util里的visualization_utils.py，修改:(加上if和它上面那一句，再将后面的缩进)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>display_str_list &#x3D; box_to_display_str_map[box]<br>  if ((“Person”) in display_str_list[0]or(“Window”) in display_str_list[0]<br>          or(“Man”) in display_str_list[0]or(“Woman”) in display_str_list[0]<br>          ):<br>      draw_bounding_box_on_image_array(<br>          image,<br>          ymin,<br>          xmin,<br>          ymax,<br>          xmax,<br>          color&#x3D;color,<br>          thickness&#x3D;0 if skip_boxes else line_thickness,<br>          display_str_list&#x3D;box_to_display_str_map[box],<br>          use_normalized_coordinates&#x3D;use_normalized_coordinates)<br>      if keypoints is not None:<br>        keypoint_scores_for_box &#x3D; None<br>        if box_to_keypoint_scores_map:<br>          keypoint_scores_for_box &#x3D; box_to_keypoint_scores_map[box]<br>        draw_keypoints_on_image_array(<br>            image,<br>            box_to_keypoints_map[box],<br>            keypoint_scores_for_box,<br>            min_score_thresh&#x3D;min_score_thresh,<br>            color&#x3D;color,<br>            radius&#x3D;line_thickness &#x2F; 2,<br>            use_normalized_coordinates&#x3D;use_normalized_coordinates,<br>            keypoint_edges&#x3D;keypoint_edges,<br>            keypoint_edge_color&#x3D;color,<br>            keypoint_edge_width&#x3D;line_thickness &#x2F;&#x2F; 2)</p>
<p>return image</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">然后发现用错模型了，应该用oid，而不是coco，coco里没有窗子。gg，树莓派应该也g了</span><br><span class="line"></span><br><span class="line">实践过程中，发现可以将原pbtxt文件中的需要的item，copy下来，然后自己创建一个my.pbtxt.调用自己的这个，没有任何问题，（其他检测的会显示成N/A）</span><br><span class="line"></span><br><span class="line">然后我们再根据这篇文章</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/qq_33507306/article/details/92847413</span><br><span class="line"></span><br><span class="line">将不显示所有的NA方框，那就能得到我们所需要的，只显示孩子和窗户的程序了</span><br><span class="line"></span><br><span class="line">使用程序将b栈视屏检测：</span><br><span class="line"></span><br><span class="line">发现问题：</span><br><span class="line"></span><br><span class="line">![image-20211103222251474](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20211103222251474.png)</span><br><span class="line"></span><br><span class="line">只能在进度条上看见检测框。？gg</span><br><span class="line"></span><br><span class="line">怀疑：检测时权重常在49到五十之间，五十的画面只有几帧，一闪而过，人眼分辨不出导致了上面的情况</span><br><span class="line"></span><br><span class="line">办法：将权重下调至40%甚至30%</span><br><span class="line"></span><br><span class="line">![image-20211104105000147](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20211104105000147.png)</span><br><span class="line"></span><br><span class="line">新增这一行。</span><br><span class="line"></span><br><span class="line"># 延迟和掉帧</span><br><span class="line"></span><br><span class="line">现在来解决这个老问题，</span><br><span class="line"></span><br><span class="line">## 思路一：</span><br><span class="line"></span><br><span class="line">使用tflite模型，</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/zjj7725/article/details/103048414</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;export_tflite_ssd_graph.py –pipeline_config_path&#x3D;object_detection&#x2F;samples&#x2F;configs&#x2F;ssd_mobilenet_v2_oid_v4.config –trained_checkpoint_prefix&#x3D;object_detection&#x2F;ssd_mobilenet_v2_oid_v4_2018_12_12&#x2F;model.ckpt –output_directory&#x3D;object_detection&#x2F;ssdtflite –add_postprocessing_op&#x3D;true</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">一定要在research下运行，不然会报错，没有protos</span><br><span class="line"></span><br><span class="line">根据这篇文章的最后一部分，将原pb模型文件转化为tflite文件，里面需要下载tensorflow1.13和bazel</span><br><span class="line"></span><br><span class="line">https://www.cnblogs.com/zjutzz/p/10182099.html</span><br><span class="line"></span><br><span class="line">根据这篇文章安装bazel：</span><br><span class="line"></span><br><span class="line">下面总结一下上两步：</span><br><span class="line"></span><br><span class="line">1. 下载tensorflow.zip，解压</span><br><span class="line">2. 下载bazel.exe,这里要将原名字重命名，原名字一大串</span><br><span class="line">3. 将上诉exe文件添加到环境变量中。</span><br><span class="line"></span><br><span class="line">生成中间文件命令</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;export_tflite_ssd_graph.py –pipeline_config_path&#x3D;&#x2F;usr&#x2F;local&#x2F;anaconda3&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train&#x2F;pipeline.config –trained_checkpoint_prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;anaconda3&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train&#x2F;model.ckpt-80000 –output_directory&#x3D;&#x2F;usr&#x2F;local&#x2F;anaconda3&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train –add_postprocessing_op&#x3D;true<br>#注意改地址，名字</p>
<p>#第二步<br>cd tensorflow-1.13.1&#x2F;<br>bazel build tensorflow&#x2F;python&#x2F;tools:freeze_graph<br>bazel build tensorflow&#x2F;lite&#x2F;toco:toco</p>
<p>#第三步<br>bazel run tensorflow&#x2F;lite&#x2F;toco:toco – <br>–input_file&#x3D;&#x2F;usr&#x2F;local&#x2F;anaconda3&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train&#x2F;tflite_graph.pb <br>–output_file&#x3D;&#x2F;usr&#x2F;local&#x2F;anaconda3&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train&#x2F;detect.tflite <br>–input_shapes&#x3D;1,300,300,3 <br>–input_arrays&#x3D;normalized_input_image_tensor <br>–output_arrays&#x3D;’TFLite_Detection_PostProcess’,’TFLite_Detection_PostProcess:1’,’TFLite_Detection_PostProcess:2’,’TFLite_Detection_PostProcess:3’ <br>–inference_type&#x3D;FLOAT <br>–allow_custom_ops</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">第二步的时候报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>ERROR: C:&#x2F;users&#x2F;windsfox&#x2F;_bazel_windsfox&#x2F;3c2menqx&#x2F;external&#x2F;io_bazel_rules_closure&#x2F;closure&#x2F;templates&#x2F;closure_java_template_library.bzl:185:15: name ‘PACKAGE_NAME’ is not defined<br>ERROR: error loading package ‘’: at C:&#x2F;users&#x2F;windsfox&#x2F;_bazel_windsfox&#x2F;3c2menqx&#x2F;external&#x2F;io_bazel_rules_closure&#x2F;closure&#x2F;defs.bzl:24:6: compilation of module ‘closure&#x2F;templates&#x2F;closure_java_template_library.bzl’ failed<br>INFO: Elapsed time: 0.255s<br>INFO: 0 processes.<br>FAILED: Build did NOT complete successfully (0 packages loaded)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">gg</span><br><span class="line"></span><br><span class="line">有找到一篇文章：https://blog.csdn.net/jiangjiang4564/article/details/107379916/?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.no_search_link&amp;spm=1001.2101.3001.4242.2</span><br><span class="line"></span><br><span class="line">![image-20211106181145735](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20211106181145735.png)</span><br><span class="line"></span><br><span class="line">心里默念，我不是最倒霉的那一个。（原来看别人倒霉是真的可以让原本难过的心情变好的）</span><br><span class="line"></span><br><span class="line">舒服了，虽然tensorflow我也装了两三天</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其实并不需要什么命令行，直接使用pb_to_tflite.py文件运行就是了，舒服了蛐蛐</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 新问题：</span><br><span class="line"></span><br><span class="line">网上有的使用lite，命令后面跟了labels文件的路径</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python3 detect_picamera.py  –model &#x2F;tmp&#x2F;detect.tflite –labels &#x2F;tmp&#x2F;coco_labels.txt<br>#又有的没跟<br>python3 TFLite_detection_webcam.py –modeldir&#x3D;Sample_TFLite_model<br>#草了，到底跟不跟啊。控制变量法<br>#乌龙，其实是要跟的，下面这个是目录，里面有模型文件和txt文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 制作label.txt文件</span><br><span class="line"></span><br><span class="line">到这里我们发现官方ssdoid模型转成的tflite文件没有和他匹配的601个分类的label.txt文件，所以tflite1项目里运行webcam.py的的时候会导致下标越界（如果我们能找到这601的个分类，可以尝试解决问题！！）</span><br><span class="line"></span><br><span class="line">通过使用pycharm中的多行替换功能将`oid_v4_label_map.pbtxt`的所有name提取出来，制作成`oid_v4_label_map.txt`（PS：文本编辑器不允许多行替换。），其中出现过下面问题（想不通）</span><br><span class="line"></span><br><span class="line">![image-20211108165504534](https://raw.githubusercontent.com/windsfox/blog_img/master/blog//image-20211108165504534.png)</span><br><span class="line"></span><br><span class="line">`（.*?）`是一个字符，`（.*）`是字符串</span><br><span class="line"></span><br><span class="line">## 重新想办法提升训练效果</span><br><span class="line"></span><br><span class="line">然后就是我们自己训练的东西，两万不行，二十万也不行，</span><br><span class="line"></span><br><span class="line">1. 另一个组员在训练100万的，成人和窗户的数据集</span><br><span class="line">2. 现在我们只使用特定的图片来检测人和窗户</span><br><span class="line"></span><br><span class="line"># 针对数据集</span><br><span class="line"></span><br><span class="line">现在怀疑是数据集出了问题，我们其实只需要特定的窗户识别，</span><br><span class="line"></span><br><span class="line">现在拍二十张寝室窗户图片，二十张室友图片，拿来训练。（注意转为csv文件的时候，jpeg文件会出问题，需要手动改一下）</span><br><span class="line"></span><br><span class="line">使用ssd_v2_coco.config训练：速度很慢，两分钟一百个steps。gg（但是gpu显存是占满了的）</span><br><span class="line"></span><br><span class="line">找了一晚上：将config文件换成ssdlite_v2_coco.config,(里面总共训练次数为一万个steps)，并且修改了里面的学习率：改为0.04（原来的为0.004）</span><br><span class="line"></span><br><span class="line">不知道是上面的哪个原因：速度又变快了（40秒一百个steps）</span><br><span class="line"></span><br><span class="line">![image-20211111120720332](https://first-bolg-bucket.oss-cn-beijing.aliyuncs.com/Typora/image-20211111120720332.png)</span><br><span class="line"></span><br><span class="line">失败</span><br><span class="line"></span><br><span class="line">开始尝试只使用两万</span><br><span class="line"></span><br><span class="line"># 偷师同学：</span><br><span class="line"></span><br><span class="line">借用同学分享的数据集，</span><br><span class="line"></span><br><span class="line">在转化为csv的时候报错：</span><br><span class="line"></span><br><span class="line">原因：python中的float类型的字符（理解一下），不能强制转化为int需要：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>int(float(member[4][0].text)),<br>int(float(member[4][1].text)),<br>int(float(member[4][1].text)),<br>int(float(member[4][1].text))</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">报错，直接运行不了。</span><br><span class="line"></span><br><span class="line">原因：这里的二三都写成一了</span><br><span class="line"></span><br><span class="line">![image-20211112180932359](C:%5CUsers%5Cwindsfox%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20211112180932359.png)</span><br><span class="line"></span><br><span class="line">报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.<br>  (0) Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.100000: ] [1.80371094]<br>         [[node ToAbsoluteCoordinates_1&#x2F;Assert&#x2F;AssertGuard&#x2F;Assert (defined at D:\code\ob_work\models\research\object_detection\core\box_list_ops.py:916) ]]<br>         [[map_1&#x2F;while&#x2F;zeros&#x2F;_2603]]<br>  (1) Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.100000: ] [1.80371094]<br>         [[node ToAbsoluteCoordinates_1&#x2F;Assert&#x2F;AssertGuard&#x2F;Assert (defined at D:\code\ob_work\models\research\object_detection\core\box_list_ops.py:916) ]]<br>0 successful operations.<br>0 derived errors ignored.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[https://blog.csdn.net/qq_36414085/article/details/101011895?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link](https://blog.csdn.net/qq_36414085/article/details/101011895?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link)</span><br><span class="line"></span><br><span class="line">这位老哥给出了解答：</span><br><span class="line"></span><br><span class="line">终于发现，借鉴的其中一个组的数据，使用的并不是像素来做标签的单位，所以才爆炸的。</span><br><span class="line"></span><br><span class="line">用别的组的</span><br><span class="line"></span><br><span class="line">然后还是报错；原因：png格式的图片不能被训练（训练时报错）。真的倒霉，有一组有十二张png图片。</span><br><span class="line"></span><br><span class="line">放弃那一组</span><br><span class="line"></span><br><span class="line">继续制作数据集，继续训练：</span><br><span class="line"></span><br><span class="line">报错：image_size must contain 3 elements[4]</span><br><span class="line"></span><br><span class="line">https://www.cnblogs.com/chay/p/10447718.html</span><br><span class="line"></span><br><span class="line">这里需要特别注意的一点是不是所有的`.jpg`文件都是三通道的。</span><br><span class="line"></span><br><span class="line">绝了，真的难受。是不是已经把所有问题都遇完了，哈哈哈哈哈哈哈</span><br><span class="line"></span><br><span class="line">打印出不是RGB的图片名字，一个一个删掉</span><br><span class="line"></span><br><span class="line">好了继续前进</span><br><span class="line"></span><br><span class="line">训练时报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]<br>         [[{ {node case&#x2F;cond&#x2F;cond_jpeg&#x2F;decode_image&#x2F;cond_jpeg&#x2F;cond_png&#x2F;cond_gif&#x2F;Assert_1&#x2F;Assert} }]]<br>         [[IteratorGetNext]]</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">https://blog.csdn.net/weixin_39942108/article/details/110484209</span><br><span class="line"></span><br><span class="line">显然这些图片也有些是改过的png格式</span><br><span class="line"></span><br><span class="line">![image-20211112232355118](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211112232355118.png)</span><br><span class="line"></span><br><span class="line">真的什么牛鬼蛇神都有</span><br><span class="line"></span><br><span class="line">终于成功了</span><br><span class="line"></span><br><span class="line">![image-20211112233402549](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211112233402549.png)</span><br><span class="line"></span><br><span class="line">报错：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>tensorflow.python.framework.errors_impl.InvalidArgumentError: input must be 4-dimensional[1,91,338,600,3]<br>         [[{ {node ResizeImage&#x2F;resize&#x2F;ResizeBilinear} }]]<br>         [[IteratorGetNext]]</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 现在运行的命令：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training&#x2F;ssdlite_mobilenet_v2_coco.config –model_dir&#x3D;training  –alsologtostderr</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看模型训练情况</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>tensorboard –logdir&#x3D;training</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">http://localhost:6006/查看</span><br><span class="line"></span><br><span class="line">![image-20211113155535044](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211113155535044.png)</span><br><span class="line"></span><br><span class="line">很显然，loss下降到五左右就不降了</span><br><span class="line"></span><br><span class="line">![image-20211113155705260](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211113155705260.png)</span><br><span class="line"></span><br><span class="line">但是效果看起来已经很好了</span><br><span class="line"></span><br><span class="line">实践途中发现了，在训练当中，是可以修改喂入的batch_size的，只不过如果改大了，训练时间会增加</span><br><span class="line"></span><br><span class="line">## 对batch_size理解：</span><br><span class="line"></span><br><span class="line">过小，不易于收敛；过大，局部最小值导致loss无法下降（2太小，16过大，效果很拉）</span><br><span class="line"></span><br><span class="line">我们选择4</span><br><span class="line"></span><br><span class="line">![image-20211114164210143](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211114164210143.png)</span><br><span class="line"></span><br><span class="line">但是正则化loss好像过拟合了</span><br><span class="line"></span><br><span class="line">我们还要随时看着</span><br><span class="line"></span><br><span class="line">![image-20211115162936171](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211115162936171.png)</span><br><span class="line"></span><br><span class="line">![image-20211115163437673](https://raw.githubusercontent.com/windsfox/blog_img/master/blog/image-20211115163437673.png)</span><br><span class="line"></span><br><span class="line">上面这张图是batch_size为8的时候的训练效果</span><br><span class="line"></span><br><span class="line">太辣了</span><br><span class="line"></span><br><span class="line"># 使用服务器训练</span><br><span class="line"></span><br><span class="line">## 白嫖的阿里服务器</span><br><span class="line"></span><br><span class="line">我发现我之前忽略了一个点，服务器虽然训练得慢，但是它能没日没夜的训练啊，他训练二十四个小时，相当于我们训练三个小时，我还有十五天的试用时间</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>#装完环境，启动conda环境<br>conda activate tf-pose<br>#在research目录下：（注意这里又用的成年人的巨量数据集了）<br>nohup TF_XLA_FLAGS&#x3D;–tf_xla_cpu_global_jit python  object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training_my –sample_1_of_n_eval_examples&#x3D;25 –alsologtostderr   &gt;&#x2F;dev&#x2F;null  2&gt;log.file &amp;</p>
<p>vim ~&#x2F;.bashrc<br>export PYTHONPATH&#x3D;$PYTHONPATH:&#x2F;usr&#x2F;local&#x2F;models&#x2F;research:&#x2F;usr&#x2F;local&#x2F;models&#x2F;research&#x2F;slim<br>source ~&#x2F;.bashrc</p>
<p>#报错，没有pycocotools，找了一晚上，最后发现<br>#1.首先安装cyphton<br>pip install cython</p>
<p>#2. 安装pycocotools<br>pip install pycocotools</p>
<h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><p>#报错：libGL.so.1: cannot open shared object file: No such file or directory<br>#<a target="_blank" rel="noopener" href="https://blog.csdn.net/agonysome/article/details/108985079%EF%BC%8C%E8%A7%A3%E5%86%B3">https://blog.csdn.net/agonysome/article/details/108985079，解决</a><br>yum install mesa-libGL.x86_64</p>
<p>#但是每次一运行，直接被killed</p>
<h1 id="https-blog-csdn-net-cxxxxxxxxxxxxx-article-details-106344235，这个老哥写了"><a href="#https-blog-csdn-net-cxxxxxxxxxxxxx-article-details-106344235，这个老哥写了" class="headerlink" title="https://blog.csdn.net/cxxxxxxxxxxxxx/article/details/106344235，这个老哥写了"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/cxxxxxxxxxxxxx/article/details/106344235%EF%BC%8C%E8%BF%99%E4%B8%AA%E8%80%81%E5%93%A5%E5%86%99%E4%BA%86">https://blog.csdn.net/cxxxxxxxxxxxxx/article/details/106344235，这个老哥写了</a></h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20211121225553817](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211121225553817.png)</span><br><span class="line"></span><br><span class="line">但是我已经改成一了，还是直接被killed，绝望</span><br><span class="line"></span><br><span class="line">## 矩池云：</span><br><span class="line"></span><br><span class="line">又看了一堆知乎和csdn，有的人说2g2c的服务器，搭个小网站都吃力。根本不用想机器学习，除非你自己做数字识别这种教学用的。</span><br><span class="line"></span><br><span class="line">于是乎了解到了矩池云这个网站：https://matpool.com/edu</span><br><span class="line"></span><br><span class="line">下午上课的时候，一个朋友说他们综合设计的费用能报销。我问了问我们组长，组长说有的指导老师是可以报销的，我们这个指导老师的实验室懂的都懂。只能自己扛。我们只能小组内分摊。</span><br><span class="line"></span><br><span class="line">### 上传object_detection目录和数据集</span><br><span class="line"></span><br><span class="line">这里发现它提供了一个网盘，刚开始不知道有什么用处。看了这篇文章后，猜测是用来同步主机里的文件的（挂载到主机的/mnt目录下），不然主机时间到后，忘了下载模型就直接gg。但是他只有5个g，再高就要自己购买了</span><br><span class="line"></span><br><span class="line">这里有一个细节：上传的zip文件，解压后，并不会用其名字新建一个文件夹当做第一层（bandzip会），而是直接将里面的所有东西摆在同一级目录</span><br><span class="line"></span><br><span class="line">![image-20211123211707431](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211123211707431.png)</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/m0_45172994/article/details/115786701</span><br><span class="line"></span><br><span class="line">购买了gpu主机之后，会获得一个ssh命令，将其输入到你笔记本的命令行。就可连接到远程（xhell和xftp用不了）</span><br><span class="line"></span><br><span class="line">或者点击下面的朱比特lab链接，直接通过浏览器连接到远程主机。</span><br><span class="line"></span><br><span class="line">跑完之后，点击主机旁边的更多，保存并释放就行了</span><br><span class="line"></span><br><span class="line">### 搭建环境</span><br><span class="line"></span><br><span class="line">https://www.cnblogs.com/matpool/p/15386008.html</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>conda info -e #查看当前系统有哪些python环境</p>
<p>conda create -n tf-pose python&#x3D;3.6</p>
<p>conda activate tf-pose<br>#搭建环境官方脚本，我已经把tf2的setup.py复制到当前文件夹下了，所以可以直接跑<br>pip install –user –upgrade pip<br>#这条语句可能运行不了，需要更新pip<br>python -m pip install –use-feature&#x3D;2020-resolver .</p>
<p>#添加到环境变量<br>vim ~&#x2F;.bashrc<br>export PYTHONPATH&#x3D;$PYTHONPATH:&#x2F;mnt:&#x2F;mnt&#x2F;slim<br>source ~&#x2F;.bashrc<br>#打印出sh: &#96;exit’: is a special builtin，开始以为是报错，但其实就是一句提示</p>
<p>#测试<br>python object_detection&#x2F;builders&#x2F;model_builder_tf2_test.py</p>
<p>#训练<br>python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training_my –sample_1_of_n_eval_examples&#x3D;25 –alsologtostderr </p>
<p>#报错：ImportError: cannot import name ‘keras_tensor’ from ‘tensorflow.python.keras.engine’ (&#x2F;root&#x2F;miniconda3&#x2F;envs&#x2F;myconda&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;tensor</p>
<h1 id="https-blog-csdn-net-weixin-41552975-article-details-117846962，根据这篇文章升级到2-5"><a href="#https-blog-csdn-net-weixin-41552975-article-details-117846962，根据这篇文章升级到2-5" class="headerlink" title="https://blog.csdn.net/weixin_41552975/article/details/117846962，根据这篇文章升级到2.5"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41552975/article/details/117846962%EF%BC%8C%E6%A0%B9%E6%8D%AE%E8%BF%99%E7%AF%87%E6%96%87%E7%AB%A0%E5%8D%87%E7%BA%A7%E5%88%B02.5">https://blog.csdn.net/weixin_41552975/article/details/117846962，根据这篇文章升级到2.5</a></h1><p>#报错：ValueError: ssd_mobilenet_v2 is not supported. See <code>model_builder.py</code> for features extractors compatible with different versions of Tensorflow<br>#网上基本没有解释，只有英文的在哪里说得不清不楚的。我们还是装回1.14<br>#报错：ImportError: cannot import name ‘resnet’ from ‘tensorflow.python.keras.applications’，网上没有解答<br>#怀疑是python3.7的错误，从新搭建3.6的环境</p>
<h1 id="报错：ImportError-libGL-so-1-cannot-open-shared-object-file-No-such-file-or-directory"><a href="#报错：ImportError-libGL-so-1-cannot-open-shared-object-file-No-such-file-or-directory" class="headerlink" title="报错：ImportError: libGL.so.1: cannot open shared object file: No such file or directory"></a>报错：ImportError: libGL.so.1: cannot open shared object file: No such file or directory</h1><h1 id="https-blog-csdn-net-qq-35516745-article-details-103822597"><a href="#https-blog-csdn-net-qq-35516745-article-details-103822597" class="headerlink" title="https://blog.csdn.net/qq_35516745/article/details/103822597"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35516745/article/details/103822597">https://blog.csdn.net/qq_35516745/article/details/103822597</a></h1><p>sudo apt update<br>sudo apt install libgl1-mesa-glx<br>#没用还是报错<br>#报错：ImportError: cannot import name ‘resnet’ from ‘tensorflow.python.keras.applications’<br>升级到1.15<br>报错没有nets，注意这个时候不要去pip install，那个不是我们需要的<br>我们要的是将slim这个文件夹放在object_detection同级，并且将其添加到PYTHONPATH中。<br>终于ok了，神奇的是我window上用的1.14却没有任何问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20211123224839618](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211123224839618.png)</span><br><span class="line"></span><br><span class="line">然后发现一个致命的问题，cuda版本不匹配，嘿嘿，gg，我是麻瓜，重新租一个</span><br><span class="line"></span><br><span class="line">但是只有2.7版本的python搭配1.15。并且显示框有问题，不能conda activate，草了。</span><br><span class="line"></span><br><span class="line">重新租用cuda10的，python3.6的</span><br><span class="line"></span><br><span class="line">终于成昆了</span><br><span class="line"></span><br><span class="line">### 训练</span><br><span class="line"></span><br><span class="line">上面那篇文章是用pycharm远程连接进行训练的。</span><br><span class="line"></span><br><span class="line">问题：</span><br><span class="line"></span><br><span class="line">1. 如果我直接用xshell，运行后台训练命令，关闭窗口后会不会直接结束进程？</span><br><span class="line">2. 如果上面可以跑，那运行完之后，还会不会扣时间（打算买50卡时，三十天的）</span><br><span class="line"></span><br><span class="line">如果上面的问题不能解决，那我们就用pycharm跑（贼几把麻烦）</span><br><span class="line"></span><br><span class="line">再三思索，决定用后台命令训练，时间方面可以看着每个step的时间，计算一下完成时间，然后到点了自己去关。（网上别人就有这么办的，应该可行）</span><br><span class="line"></span><br><span class="line">![image-20211123232529260](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211123232529260.png)</span><br><span class="line"></span><br><span class="line">![image-20211123232654738](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211123232654738.png)</span><br><span class="line"></span><br><span class="line">batchsize为8，是要比我笔记本的47秒快一点</span><br><span class="line"></span><br><span class="line">将batch改为16，并后台运行</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>nohup python  object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training_my&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training_my –sample_1_of_n_eval_examples&#x3D;25 –alsologtostderr   &gt;&#x2F;dev&#x2F;null  2&gt;log.file &amp;</p>
<p>tensorboard –logdir&#x3D;training_my</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">https://www.cnblogs.com/matpool/p/14504908.html</span><br><span class="line"></span><br><span class="line">根据这篇文章，使用隧道连接，有意思的是xshell中只允许ip地址，不允许域名，所以我们只能使用命令行，进行隧道连接</span><br><span class="line"></span><br><span class="line">因为命令行会dns解析。</span><br><span class="line"></span><br><span class="line">睡觉喽。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>ssh -p 26937 -NL 6006:localhost:6006 <a href="mailto:&#114;&#111;&#111;&#x74;&#x40;&#x68;&#x7a;&#x2d;&#x74;&#51;&#46;&#x6d;&#97;&#x74;&#112;&#x6f;&#111;&#108;&#46;&#99;&#x6f;&#x6d;">&#114;&#111;&#111;&#x74;&#x40;&#x68;&#x7a;&#x2d;&#x74;&#51;&#46;&#x6d;&#97;&#x74;&#112;&#x6f;&#111;&#108;&#46;&#99;&#x6f;&#x6d;</a>(最后这个是主机名)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">然后就可在本地6006访问远程的tensorBoard了</span><br><span class="line"></span><br><span class="line">![image-20211124124146403](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124124146403.png)</span><br><span class="line"></span><br><span class="line">![image-20211124124103368](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124124103368.png)</span><br><span class="line"></span><br><span class="line">可以看到对大物体的检测效果已经很好了，但是对小物体的检测效果却很垃圾（这一点我们尽量忽略，因为我们主要是在一个对准窗户的情景下，这样婴儿和窗户都会显得很大）</span><br><span class="line"></span><br><span class="line">![image-20211124131205474](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124131205474.png)</span><br><span class="line"></span><br><span class="line">现在的问题：检测人的效果非常好，但是窗户基本检测不出来了</span><br><span class="line"></span><br><span class="line"># 训练两个模型，</span><br><span class="line"></span><br><span class="line">一个检测窗户，一个检测人体，检测人体用上面那个就OK了</span><br><span class="line"></span><br><span class="line">现在我们来制作窗户数据集：</span><br><span class="line"></span><br><span class="line">制作好后训练：但这次采用coco的配置文件</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>nohup python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training&#x2F;ssdlite_mobilenet_v2_coco.config –model_dir&#x3D;training  –alsologtostderr   &gt;&#x2F;dev&#x2F;null  2&gt;log.file &amp;</p>
<p>ssh -p 29689 -NL 6006:localhost:6006 <a href="mailto:&#x72;&#111;&#111;&#116;&#64;&#x68;&#x7a;&#x2d;&#116;&#x33;&#46;&#x6d;&#x61;&#116;&#112;&#x6f;&#111;&#x6c;&#46;&#99;&#111;&#x6d;">&#x72;&#111;&#111;&#116;&#64;&#x68;&#x7a;&#x2d;&#116;&#x33;&#46;&#x6d;&#x61;&#116;&#112;&#x6f;&#111;&#x6c;&#46;&#99;&#111;&#x6d;</a></p>
<p>tensorboard –logdir&#x3D;training</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20211124184713604](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124184713604.png)</span><br><span class="line"></span><br><span class="line">我现在怀疑是coco模型的问题。</span><br><span class="line"></span><br><span class="line">![image-20211124203917869](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124203917869.png)</span><br><span class="line"></span><br><span class="line">![image-20211124204214095](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124204214095.png)</span><br><span class="line"></span><br><span class="line">实际效果不太行</span><br><span class="line"></span><br><span class="line">改用oid模型：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>nohup python object_detection&#x2F;model_main.py –pipeline_config_path&#x3D;training&#x2F;ssd_mobilenet_v2_oid_v4.config –model_dir&#x3D;training  –alsologtostderr   &gt;&#x2F;dev&#x2F;null  2&gt;log.file &amp;</p>
<p>python object_detection&#x2F;export_inference_graph.py –input_type&#x3D;image_tensor –pipeline_config_path&#x3D;training&#x2F;ssd_mobilenet_v2_oid_v4.config –trained_checkpoint_prefix&#x3D;training&#x2F;model.ckpt-25390 –output_directory&#x3D;wb3_inference_graph</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">刚开始batchsize为8，二十多秒一个step，训练了一万个steps，两种loss都没下降过，后来改成24，才开始下降了</span><br><span class="line"></span><br><span class="line">![image-20211125144622088](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211125144622088.png)</span><br><span class="line"></span><br><span class="line">白天的效果非常好</span><br><span class="line"></span><br><span class="line">但是我想晚上效果也好：将上一步的batchsize改为16，从0开始训练：</span><br><span class="line"></span><br><span class="line">![image-20211125144803397](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211125144803397.png)</span><br><span class="line"></span><br><span class="line">可以看到分类loss不会过高的涨幅了，所以理论来说这个模型应该非常完美。</span><br><span class="line"></span><br><span class="line">![image-20211125150648684](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211125150648684.png)</span><br><span class="line"></span><br><span class="line">然而晚上效果还是不好，放弃了。到这里就算完成了</span><br><span class="line"></span><br><span class="line"># 一个Python文件</span><br><span class="line"></span><br><span class="line">同时使用两个模型，进行检测：</span><br><span class="line"></span><br><span class="line">![image-20211124210617129](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211124210617129.png)</span><br><span class="line"></span><br><span class="line">注意到这里，说明不能在一个python中运行两个模型，因为它是相当于在模型里跑图。因为程序是顺序执行，如果你要加载两个，那必须等前一个结束了才能加载第二个模型，所以永远不可能。</span><br><span class="line"></span><br><span class="line">所以我们编写两个python文件，分别检测人和窗户的坐标，然后发送到服务器。（想过两个Python进程传递变量的方法，网上说的贼复杂，果断放弃）</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>nohup python object_detection&#x2F;DetectBabyFinal.py   &gt;&#x2F;dev&#x2F;null  2&gt;log.file &amp;<br>nohup python object_detection&#x2F;DetectWindowFinal.py   &gt;&#x2F;dev&#x2F;null  2&gt;log.file &amp;</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 老师提问：</span><br><span class="line"></span><br><span class="line">1. 为什么你的准确率这么低啊？我看别人的准确率都是80%90%，你这怎么是40%50%？</span><br><span class="line"></span><br><span class="line">   答：这是置信度，并不是准确率，别人置信度高，是他调的比较高；我们之前使用自己找的两百多张图片做训练的时候，训练出来的置信度也很高，但是会出现过拟合的状况，将一些类人形物体也检测出来。后来我们用了coco数据集中的人体数据集和imgnet2012中的人体和窗户数据集，置信度就下来了，但是不会出现将其他检测为人体的情况。准确率是指有没有检测出来人，比如说我们这个视屏里有一个小孩，我们检测出来了，这个准确率就是100%，不能一直检测一方面是里面的人可能部分被一些东西挡住，或者移动导致可能在一瞬间检测不出来。</span><br><span class="line"></span><br><span class="line"># 答辩：</span><br><span class="line"></span><br><span class="line">## 机器学习步骤：</span><br><span class="line"></span><br><span class="line">我们使用tensorflow的object_detection做窗户和人的目标检测，因为考虑到现在都是推拉窗户，所以在制作数据集的时候并没有做开关窗户的分类，只做了窗户标签和人的标签。刚开始打算用一个模型同时检测人和窗户，树莓派计算完是否危险后，发送危险信号给服务器；但是估计因为数据量太小或者二者比例问题，效果始终很差，所以我们选择一个模型检测人，一个模型检测窗户，然后将两个坐标发送给服务器，由服务器来计算是否危险状态。</span><br><span class="line"></span><br><span class="line">### 数据集制作：</span><br><span class="line"></span><br><span class="line">- 将自己搜罗的数据集合imgnet2012中部分挑选出来的数据集整合（）：</span><br><span class="line">- ![image-20211231193535350](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211231193535350.png)</span><br><span class="line">- ![image-20211231192759170](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211231192759170.png)</span><br><span class="line">- 制作成tfrecord文件：</span><br><span class="line">- ![image-20211231193111109](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211231193111109.png)</span><br><span class="line"></span><br><span class="line">1. 训练：</span><br><span class="line"></span><br><span class="line">   - 环境：使用矩池云在云上训练，tensorflow版本1.14.0：</span><br><span class="line"></span><br><span class="line">   - 运行命令：</span><br><span class="line"></span><br><span class="line">   - \```shell</span><br><span class="line">     python object_detection/model_main.py –pipeline_config_path=training/ssd_mobilenet_v2_coco.config –model_dir=training –alsologtostderr</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code> - 导出模型：
 
 - ```shell
   python object_detection/export_inference_graph.py --input_type=image_tensor --pipeline_config_path=training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix=training/model.ckpt-200000 --output_directory=wb2_inference_graph
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   - 效果检测：</span><br><span class="line"></span><br><span class="line">   - ![image-20211231193911793](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211231193911793.png)</span><br><span class="line"></span><br><span class="line">   - ![image-20211231193946364](https://gitee.com/gitzuo/blog2021/raw/master/blog2021/image-20211231193946364.png)</span><br><span class="line"></span><br><span class="line">### 代码分析：</span><br><span class="line"></span><br><span class="line">主要还是数据集的处理比较麻烦，训练有现成的python文件</span><br><span class="line"></span><br><span class="line">#### 数据集制作：</span><br><span class="line"></span><br><span class="line">1. 查询不是三通道的图片</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</code></pre>
<p>   from PIL import Image<br>   import os</p>
<h1 id="查询一个文件夹下所有不是三通道的图片"><a href="#查询一个文件夹下所有不是三通道的图片" class="headerlink" title="查询一个文件夹下所有不是三通道的图片"></a>查询一个文件夹下所有不是三通道的图片</h1><p>   path &#x3D; ‘imgs_xml&#x2F;‘ #图片目录<br>   for file in os.listdir(path):</p>
<pre><code>    extension = file.split(&#39;.&#39;)[-1]
    if extension == &#39;jpg&#39;:
          fileLoc = path+file
          img = Image.open(fileLoc)
          if img.mode != &#39;RGB&#39;:
                print(file+&#39;, &#39;+img.mode)
</code></pre>
   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2. 查看图片编码形式</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>   import imghdr,os</p>
<h1 id="查询一个文件夹下所有不是jpeg格式的图片"><a href="#查询一个文件夹下所有不是jpeg格式的图片" class="headerlink" title="查询一个文件夹下所有不是jpeg格式的图片"></a>查询一个文件夹下所有不是jpeg格式的图片</h1><p>   #filename &#x3D; ‘img.py’</p>
<p>   from PIL import Image<br>   import os<br>   path &#x3D; ‘imgs_xml&#x2F;‘ #图片目录<br>   for file in os.listdir(path):<br>       filename &#x3D; path+file<br>       imgType &#x3D; imghdr.what(filename)<br>       if imgType:<br>           if imgType!&#x3D;”jpeg”:<br>               print(filename+”————“+imgType)<br>           # newName &#x3D; (filename + ‘.’ + imgType)<br>           # os.rename(filename,newName)<br>       else:<br>           i&#x3D;0<br>           # os.remove(filename)<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">3. 提取图片信息到csv</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>   #读取文件中的标签名<br>   def xmlPath_list_to_df(xmlPath_list):<br>       xmlContent_list &#x3D; []<br>       for xmlPath in xmlPath_list:<br>           tree &#x3D; ET.parse(xmlPath)<br>           root &#x3D; tree.getroot()</p>
<pre><code>       for member in root.findall(&#39;object&#39;):
           # print(member[0].text)
           # print(member[0])
           if 1-(member[0].text in [&quot;windows&quot;,&quot;openingwindow&quot;,&quot;closedwindow&quot;]):
               continue
               # member[0].text = &quot;baby&quot; ,因为我们不需要baby了，乌龙，但是还有person
           if(member[0].text in [&quot;windows&quot;,&quot;openingwindow&quot;,&quot;closedwindow&quot;]):
               member[0].text=&quot;windows&quot;

           sam=root.find(&#39;filename&#39;).text
           result = (&#39;jpg&#39; in root.find(&#39;filename&#39;).text)
           if(1-result):
               sam=root.find(&#39;filename&#39;).text+&#39;.jpg&#39;

           value = (sam,
                    int(root.find(&#39;size&#39;)[0].text),
                    int(root.find(&#39;size&#39;)[1].text),
                    member[0].text,
                    int(member[4][0].text),
                    int(member[4][1].text),
                    int(member[4][2].text),
                    int(member[4][3].text)
                    )
           xmlContent_list.append(value)
   column_name = [&#39;filename&#39;, &#39;width&#39;, &#39;height&#39;, &#39;class&#39;, &#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]
   xmlContent_df = pd.DataFrame(xmlContent_list, columns=column_name)
   return xmlContent_df
</code></pre>
<p>   #保存地址<br>   def dirPath_to_csv(dirPath):<br>       fileName_list &#x3D; os.listdir(dirPath)<br>       all_xmlPath_list &#x3D; [os.path.join(dirPath, fileName) for fileName in fileName_list if ‘.xml’ in fileName]<br>       train_xmlPath_list, test_xmlPath_list &#x3D; train_test_split(all_xmlPath_list, test_size&#x3D;0.1, random_state&#x3D;1)<br>       train_df &#x3D; xmlPath_list_to_df(train_xmlPath_list)<br>       train_df.to_csv(‘train.csv’)<br>       print(‘成功产生文件train.csv,训练集共有%d张图片’ % len(train_xmlPath_list))<br>       test_df &#x3D; xmlPath_list_to_df(test_xmlPath_list)<br>       test_df.to_csv(‘test.csv’)<br>       print(‘成功产生文件test.csv,测试集共有%d张图片’ % len(test_xmlPath_list))</p>
<p>   #调用主函数<br>   dirPath_to_csv(‘imgs_xml’)<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">4. 转化为record文件</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>   #读取函数<br>   def csv2tfrecord(csv_path, imageDir_path, tfrecord_path):<br>       objectInfo_df &#x3D; pd.read_csv(csv_path)<br>       tfrecord_writer &#x3D; tf.python_io.TFRecordWriter(tfrecord_path)<br>       for filename, group in objectInfo_df.groupby(‘filename’):<br>           height &#x3D; group.iloc[0][‘height’]<br>           width &#x3D; group.iloc[0][‘width’]<br>           filename_bytes &#x3D; filename.encode(‘utf-8’)<br>           image_path &#x3D; os.path.join(imageDir_path, filename)<br>           # print(image_path)<br>           with open(image_path, ‘rb’) as file:<br>               encoded_jpg &#x3D; file.read()<br>           image_format &#x3D; b’jpg’<br>           xmin_list &#x3D; list(group[‘xmin’] &#x2F; width)<br>           xmax_list &#x3D; list(group[‘xmax’] &#x2F; width)<br>           ymin_list &#x3D; list(group[‘ymin’] &#x2F; height)<br>           ymax_list &#x3D; list(group[‘ymax’] &#x2F; height)<br>           classText_list &#x3D; [classText.encode(‘utf-8’) for classText in group[‘class’]]<br>           classLabel_list &#x3D; [classText_to_classLabel(classText) for classText in group[‘class’]]<br>           tf_example &#x3D; tf.train.Example(<br>               features &#x3D; tf.train.Features(<br>                   feature &#x3D; {<br>                       ‘image&#x2F;height’: dataset_util.int64_feature(height),<br>                       ‘image&#x2F;width’: dataset_util.int64_feature(width),<br>                       ‘image&#x2F;filename’: dataset_util.bytes_feature(filename_bytes),<br>                       ‘image&#x2F;source_id’: dataset_util.bytes_feature(filename_bytes),<br>                       ‘image&#x2F;encoded’: dataset_util.bytes_feature(encoded_jpg),<br>                       ‘image&#x2F;format’: dataset_util.bytes_feature(image_format),<br>                       ‘image&#x2F;object&#x2F;bbox&#x2F;xmin’: dataset_util.float_list_feature(xmin_list),<br>                       ‘image&#x2F;object&#x2F;bbox&#x2F;xmax’: dataset_util.float_list_feature(xmax_list),<br>                       ‘image&#x2F;object&#x2F;bbox&#x2F;ymin’: dataset_util.float_list_feature(ymin_list),<br>                       ‘image&#x2F;object&#x2F;bbox&#x2F;ymax’: dataset_util.float_list_feature(ymax_list),<br>                       ‘image&#x2F;object&#x2F;class&#x2F;text’: dataset_util.bytes_list_feature(classText_list),<br>                       ‘image&#x2F;object&#x2F;class&#x2F;label’: dataset_util.int64_list_feature(classLabel_list),<br>                   }))<br>           tfrecord_writer.write(tf_example.SerializeToString())<br>       tfrecord_writer.close()<br>       print(‘成功产生tfrecord文件，保存在路径:%s’ %tfrecord_path)</p>
<p>   #目标检测的类别不同，需要修改此处<br>   def classText_to_classLabel(row_label):<br>       if row_label &#x3D;&#x3D; ‘windows’:<br>           return 1<br>       elif row_label &#x3D;&#x3D; ‘baby’:<br>           return 2<br>       else:<br>           return None</p>
<pre><code>   #保存地址
</code></pre>
<p>   dir_name &#x3D; ‘training’<br>   if not os.path.isdir(dir_name):<br>       os.mkdir(dir_name)<br>   csv2tfrecord(‘train.csv’, ‘imgs_xml’, ‘training&#x2F;train.tfrecord’)<br>   csv2tfrecord(‘test.csv’, ‘imgs_xml’, ‘training&#x2F;test.tfrecord’)<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   #### 训练</span><br><span class="line"></span><br><span class="line">5. 配置config文件：ssd_mobilenet_v2_coco.config（我们使用官方提供的这个模型，轻便所以很多人使用，对数据集不大的需求比较友好）。原代码太多，不做展示；主要修改如下：</span><br><span class="line"></span><br><span class="line">   - 配置自己的数据集地址</span><br><span class="line">   - 配置标签文件地址和标签数量</span><br><span class="line">   - 配置训练batch_size</span><br><span class="line">   - 配置模型保存时间</span><br><span class="line">   - 配置预训练模型</span><br><span class="line">   - 配置总训练步数</span><br><span class="line"></span><br><span class="line">6. 配置标签文件如下：</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>   item {<br>       name : ‘windows’<br>       id : 1<br>   }<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">7. 训练：</span><br><span class="line"></span><br><span class="line">   - 配置gpu环境：</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>   import os</p>
<h1 id="os-environ-‘CUDA-VISIBLE-DEVICES’-x3D-‘-x2F-device-GPU-0’-1"><a href="#os-environ-‘CUDA-VISIBLE-DEVICES’-x3D-‘-x2F-device-GPU-0’-1" class="headerlink" title="os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; ‘&#x2F;device:GPU:0’"></a>os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; ‘&#x2F;device:GPU:0’</h1><p>   os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; “0”<br>   os.environ[“TF_FORCE_GPU_ALLOW_GROWTH”] &#x3D;”true”</p>
<h1 id="os-environ-“CUDA-VISIBLE-DEVICES”-x3D-“-1”-显然不行，直接要两百多秒了，用gpu只需要三十秒"><a href="#os-environ-“CUDA-VISIBLE-DEVICES”-x3D-“-1”-显然不行，直接要两百多秒了，用gpu只需要三十秒" class="headerlink" title="os.environ[“CUDA_VISIBLE_DEVICES”] &#x3D; “-1” # 显然不行，直接要两百多秒了，用gpu只需要三十秒"></a>os.environ[“CUDA_VISIBLE_DEVICES”] &#x3D; “-1” # 显然不行，直接要两百多秒了，用gpu只需要三十秒</h1><p>   os.environ[‘TF_CPP_MIN_LOG_LEVEL’] &#x3D; ‘3’</p>
<p>   &#96;&#96;&#96;</p>
<ul>
<li>运行官方main文件</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1/" data-id="cl2r8w6dx0004swvs3n56bxer" data-title="综合设计" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1%E6%88%90%E5%8A%9F/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">综合设计成功</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1/">综合设计</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1%E6%88%90%E5%8A%9F/">综合设计成功</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">吴恩达机器学习</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E7%88%AC%E8%99%AB/">爬虫</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E9%98%BF%E9%87%8C%E4%BA%91/">阿里云</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>