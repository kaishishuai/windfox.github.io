<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>爬虫 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="第一章：requests模块步骤 导入requests模块 指定url UA伪装 参数params response获取爬取结果 持久化存储（list_data &#x3D; response.text(json之类的)）  ps：response.text和response.json()一个有括号一个没有括号 第二章：数据解析聚焦爬虫：爬取页面中指定的内容。 编码流程：  指定url 发起请求">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫">
<meta property="og:url" content="http://example.com/2022/05/04/%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="第一章：requests模块步骤 导入requests模块 指定url UA伪装 参数params response获取爬取结果 持久化存储（list_data &#x3D; response.text(json之类的)）  ps：response.text和response.json()一个有括号一个没有括号 第二章：数据解析聚焦爬虫：爬取页面中指定的内容。 编码流程：  指定url 发起请求">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog2022/image-20210122232346354.png">
<meta property="article:published_time" content="2022-05-04T07:19:59.000Z">
<meta property="article:modified_time" content="2022-05-04T08:05:28.698Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/windsfox/blog_img/master/blog2022/image-20210122232346354.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.1.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-爬虫" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/04/%E7%88%AC%E8%99%AB/" class="article-date">
  <time class="dt-published" datetime="2022-05-04T07:19:59.000Z" itemprop="datePublished">2022-05-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      爬虫
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="第一章：requests模块"><a href="#第一章：requests模块" class="headerlink" title="第一章：requests模块"></a>第一章：requests模块</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li>导入requests模块</li>
<li>指定url</li>
<li>UA伪装</li>
<li>参数params</li>
<li>response获取爬取结果</li>
<li>持久化存储（list_data &#x3D; response.text(json之类的)）</li>
</ol>
<p>ps：response.text和response.json()一个有括号一个没有括号</p>
<h1 id="第二章：数据解析"><a href="#第二章：数据解析" class="headerlink" title="第二章：数据解析"></a>第二章：数据解析</h1><h2 id="聚焦爬虫："><a href="#聚焦爬虫：" class="headerlink" title="聚焦爬虫："></a>聚焦爬虫：</h2><p>爬取页面中指定的内容。</p>
<p>编码流程：</p>
<ol>
<li>指定url</li>
<li>发起请求</li>
<li>获取相应数据</li>
<li>数据解析</li>
<li>持久化存储</li>
</ol>
<h2 id="数据解析分类"><a href="#数据解析分类" class="headerlink" title="数据解析分类"></a>数据解析分类</h2><ol>
<li><p>正则：ex &#x3D;(填div中的对应内容，使用（.<em>?）获取想得到的标签，或者标签里的属性，多余的数据用.</em>?省略)</p>
</li>
<li><p>bx4：实例化BeautifulSoup：(from bs4 import BeautifulSoup)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#将本地的html文档的数据加载到该对象中</span><br><span class="line">fp = open(&#x27;./test.html&#x27;,&#x27;r&#x27;,encoding =&#x27;utf-8&#x27;)</span><br><span class="line">soup = BeautifulSoup(fp,&#x27;lxml&#x27;)</span><br><span class="line">print(soup)</span><br><span class="line">#网页中的html对象</span><br><span class="line">page_text = response.text</span><br><span class="line">soup = BeautifulSoup(page_text,&#x27;lxml&#x27;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">soup.tagname  #返回该标签名第一次出现的那个标签</span><br><span class="line">soup.find(&#x27;div&#x27;，class_= &#x27;song&#x27;) #返回该属性的div</span><br><span class="line">soup.find_all(&#x27;a&#x27;)</span><br><span class="line"></span><br><span class="line">select(&#x27;某种选择器（id,class,标签。。。。选择器))，返回的是一个列表</span><br><span class="line">soup.select(&#x27;.tang&gt;ul&gt;li&gt;a&#x27;)[0] #拿到a标签列表中的第一个a标签</span><br><span class="line">soup.select(&#x27;.tang&gt;ul&gt; a&#x27;)[0] #空格表示多个层级</span><br><span class="line">soup.a.text/get_text/string #string只能获取该标签下的直系文本内容，text获取全部文本内容</span><br><span class="line">soup.a[&#x27;href&#x27;] # 获取标签中的属性值</span><br></pre></td></tr></table></figure>
</li>
<li><p>xpath（重点，通用性强）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.实例化一个etree对象，并且需要将被解析的页面源码数据加载到该对象中</span><br><span class="line">2.调用etree对象中的xpath种方法结合xpath表达式实现标签的定位和内容的捕获</span><br><span class="line">3.实例化对象：etree.parse(filepath)(本地)；etree.HTML（page_text）（网页）</span><br><span class="line">4.xpath（&#x27;xpath表达式&#x27;）：</span><br><span class="line">	r = tree.xpath(&#x27;/html/body/div&#x27;) #返回一个列表</span><br><span class="line">	r = tree.xpath(&#x27;/html//div&#x27;) #两个斜杠表示多个层级</span><br><span class="line">	r = tree.xpath(&#x27;//div[@class=&#x27;song&#x27;]/p[3]&#x27;) # 取出来p标签列表中的第四个元素</span><br><span class="line">	r = tree.xpath(&#x27;//div/[@class=&quot;tang&quot;]//li[5]/a/text()&#x27;)[0] #取出来一个标签返回的也是列表，所以加上索引0，表示第一个元素</span><br><span class="line">	/@attrName（/@src） #取属性值</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="数据解析原理"><a href="#数据解析原理" class="headerlink" title="数据解析原理"></a>数据解析原理</h2><ol>
<li>解析的局部文本内容都会在标签纸剑或者标签对应的属性中进行存储</li>
<li>进行指定标签的定位</li>
<li>标签或者标签对应的属性中所存储的数据值进行提取（解析）</li>
</ol>
<h1 id="第三章：反爬机制"><a href="#第三章：反爬机制" class="headerlink" title="第三章：反爬机制"></a>第三章：反爬机制</h1><h2 id="验证码"><a href="#验证码" class="headerlink" title="验证码"></a>验证码</h2><p>使用第三方识别验证码平台（超级鹰）,代码已经封装好了</p>
<p>chaojiying.PostPic(im,1902)返回的字典的第三个键值对的values为所需要的验证码值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chaojiying = Chaojiying_Client(&#x27;用户名&#x27;, &#x27;密码&#x27;, &#x27;912044&#x27;)  # 用户中心&gt;&gt;软件ID 生成一个替换 96001</span><br><span class="line">im = open(file_path, &#x27;rb&#x27;).read()  # 本地图片文件路径 来替换 a.jpg 有时WIN系统须要//</span><br><span class="line">print(list((chaojiying.PostPic(im, 1902)).values())[3])  # 1902 验证码类型  </span><br></pre></td></tr></table></figure>

<p>ps：验证是否登录成功：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(url=url,headers=headers,data=data)</span><br><span class="line">print(response.status_code)</span><br><span class="line">#如果打印200，证明登录成功</span><br></pre></td></tr></table></figure>

<h2 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h2><ol>
<li><p>来源：登录模拟的post请求后，有服务器端创建</p>
</li>
<li><p>session会话对象：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">作用：1.可以在请求的时候发送；2.如果请求过程产生了cookie会被自动存储到该session对象中</span><br><span class="line"></span><br><span class="line">exp：</span><br><span class="line">    session = requests.Session()</span><br><span class="line"></span><br><span class="line">    user_url = &#x27;https://www.chaojiying.com/user/login/&#x27;</span><br><span class="line">    data =&#123;</span><br><span class="line">        &#x27;user&#x27;: &#x27;winsfox&#x27;,</span><br><span class="line">        &#x27;pass&#x27;: &#x27;510623zmh&#x27;,</span><br><span class="line">        &#x27;imgtxt&#x27;:result,</span><br><span class="line">        &#x27;act&#x27;: &#x27;1&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">    #（2）使用session进行post发送</span><br><span class="line">    response = session.post(url=user_url,headers=headers,data=data)</span><br><span class="line">    print(response.status_code)</span><br><span class="line">    detail_url = &#x27;https://www.chaojiying.com/user/&#x27;</span><br><span class="line"></span><br><span class="line">    detail_page_text = session.get(url=detail_url,headers=headers).text</span><br><span class="line">    with open(&#x27;my chaojiying.html&#x27;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) as fp:</span><br><span class="line">        fp.write(detail_page_text)</span><br></pre></td></tr></table></figure>

<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2></li>
</ol>
<p>破解封IP这种反爬机制</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">——代理服务器。</span><br><span class="line">代理的作用：</span><br><span class="line">		———突破IP访问的限制</span><br><span class="line">		———隐藏自身真实IP</span><br><span class="line">代理相关网站：</span><br><span class="line">		———快代理</span><br><span class="line">		———西祠代理</span><br><span class="line">		———www.goubanjia.com</span><br><span class="line">代理IP的类型：</span><br><span class="line">		——https；http</span><br><span class="line">代理IP的匿名的：</span><br><span class="line">		——透明：服务器知道该次请求使用了代理；也知道真实的Ip</span><br><span class="line">		——匿名：知道使用了代理，但不知道真实的Ip</span><br><span class="line">		——高匿：不知道使用了代理更不知道本机的真实Ip（遇到封IP的反扒机制需要用这个）</span><br></pre></td></tr></table></figure>

<p>ps:一个网站登录上后，再用爬虫爬的时候可能找不到验证码的位置</p>
<h1 id="PS"><a href="#PS" class="headerlink" title="PS:"></a>PS:</h1><ol>
<li>有时候拿到的src不全，需要进行字符串拼接</li>
<li>div的class中有些无法获取，如：<img src="https://raw.githubusercontent.com/windsfox/blog_img/master/blog2022/image-20210122232346354.png" alt="image-20210122232346354"></li>
<li>在使用etree.xpath()的时候需要删去，如</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a_list = tree.xpath(&#x27;//div[@class=&quot;box col3 ws_block&quot;]&#x27;)</span><br></pre></td></tr></table></figure>

<h1 id="第四章：高性能异步爬虫"><a href="#第四章：高性能异步爬虫" class="headerlink" title="第四章：高性能异步爬虫"></a>第四章：高性能异步爬虫</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">原因：发送请求会有延时，导致阻塞，后面的url请求</span><br><span class="line">	方式1：多线程（不建议使用，耗费cpu资源）</span><br><span class="line">	方式2：线程池（效率不明显，适当使用）</span><br><span class="line">	方法3：单线程+异步协程（推荐）</span><br></pre></td></tr></table></figure>

<p>PS：在text中找不到元素就是通过ajax加载的，要用抓包工具找</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get()发起的请求是基于同步的，不能用在异步协程中，必须使用基于异步的网络请求的模块：aiohttp</span><br></pre></td></tr></table></figure>

<h1 id="第五章：动态加载数据处理"><a href="#第五章：动态加载数据处理" class="headerlink" title="第五章：动态加载数据处理"></a>第五章：动态加载数据处理</h1><h2 id="模拟浏览器操作：selenium"><a href="#模拟浏览器操作：selenium" class="headerlink" title="模拟浏览器操作：selenium"></a>模拟浏览器操作：selenium</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">selenium模块</span><br><span class="line">	-便捷的获取网站中的动态加载数据</span><br><span class="line">	-便捷的实现模拟登陆</span><br><span class="line">	-基于浏览器自动化的一个模块</span><br><span class="line">步骤：</span><br><span class="line">	——pip install selenium</span><br><span class="line">	——下载对应浏览器版本的驱动程序</span><br><span class="line">	——实例化一个浏览器对象</span><br><span class="line">	——编写基于浏览器自动化的操作代码</span><br><span class="line">相关函数：</span><br><span class="line">	bro.get(url)</span><br><span class="line">	search_input = bro.find_element_by_id(&#x27;q&#x27;) # 根据id查找元素（其他的选择器也行）</span><br><span class="line">	bro.execute_script(&#x27;widnow.scrollTo(0,document.body.scrollHeight)&#x27;) #执行js程序</span><br><span class="line">	botton = (找到的一个input元素)；botton.click()</span><br><span class="line">	bro.back() #回退上一个页面；forward</span><br><span class="line">	bro.quit()</span><br><span class="line">	send_keys(字符串) #标签交互</span><br><span class="line">selenlium处理iframe:</span><br><span class="line">	如果定位的标签存在与iframe标签中，必须使用switch_to.frame(id)</span><br><span class="line">	动作链（拖动）：from selenium。webdriver import ActionChains</span><br><span class="line">		实例化一个动作链对象：action = ActionChains（bro）</span><br><span class="line">		click_and_hold(div):长按且点击操作</span><br><span class="line">		move_by_offset(x,y)</span><br><span class="line">		perform()让动作链立即执行</span><br><span class="line">		action.release()释放动作链对象</span><br></pre></td></tr></table></figure>

<h3 id="无头浏览器-反检测："><a href="#无头浏览器-反检测：" class="headerlink" title="无头浏览器-反检测："></a>无头浏览器-反检测：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from time import sleep</span><br><span class="line">#实现无可视化界面的操作</span><br><span class="line">from selenium.webdriver.chrome.options import Options</span><br><span class="line">#实现规避操作</span><br><span class="line">from selenium.webdriver import ChromeOptions</span><br><span class="line"></span><br><span class="line">#实现无可视化界面</span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(&#x27;--headless&#x27;)</span><br><span class="line">chrome_options.add_argument(&#x27;--disable-gpu&#x27;)</span><br><span class="line"></span><br><span class="line">#实现检测规避</span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_experimental_option(&#x27;excludeSwitches&#x27;,[&#x27;enable-automation&#x27;])</span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=&#x27;./chromedriver.exe&#x27;,chrome_options=chrome_options,options=option)</span><br><span class="line"></span><br><span class="line">#无可视化界面</span><br><span class="line">bro.get(&#x27;https://www.baidu.com&#x27;)</span><br><span class="line">print(bro.page_source)</span><br><span class="line">sleep(2)</span><br><span class="line">bro.quit()</span><br><span class="line">其中使用的是bro.page_source返回页面详情数据</span><br></pre></td></tr></table></figure>

<h3 id="点击式验证码："><a href="#点击式验证码：" class="headerlink" title="点击式验证码："></a>点击式验证码：</h3><p>参看源码-&gt;自制-&gt;pachong-&gt;第五章：动态加载数据处理-&gt;识别验证码(完成).py</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/05/04/%E7%88%AC%E8%99%AB/" data-id="cl2r8w6dz0005swvs049t92y2" data-title="爬虫" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/05/04/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          吴恩达机器学习
        
      </div>
    </a>
  
  
    <a href="/2022/05/04/%E9%98%BF%E9%87%8C%E4%BA%91/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">阿里云</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1/">综合设计</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E7%BB%BC%E5%90%88%E8%AE%BE%E8%AE%A1%E6%88%90%E5%8A%9F/">综合设计成功</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">吴恩达机器学习</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E7%88%AC%E8%99%AB/">爬虫</a>
          </li>
        
          <li>
            <a href="/2022/05/04/%E9%98%BF%E9%87%8C%E4%BA%91/">阿里云</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>